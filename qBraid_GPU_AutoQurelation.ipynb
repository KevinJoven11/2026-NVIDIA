{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca970d30-f392-457e-b0de-71e45effb82a",
   "metadata": {},
   "source": [
    "# GPU Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960af07-4759-472f-9371-b01649f02b9e",
   "metadata": {},
   "source": [
    "## GPU vs CPU vs GPU seed only vs ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3ca8c8-1bf9-46a6-98ee-374935609a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      " CPU vs GPU MTS Benchmark Results (LABS)\n",
      "==========================================================================================\n",
      " N  reference_energy  cpu_energy  cpu_runtime_s  gpu_seedonly_energy  gpu_seedonly_runtime_s  gpu_energy  gpu_runtime_s  cpu_gap_%  gpu_gap_%  cpu_gpu_energy_match\n",
      "10                13        13.0         1.0020                 13.0                  1.0043        13.0        24.4374        0.0        0.0                  True\n",
      "12                10        10.0         1.8730                 10.0                  1.8976        10.0        45.0493        0.0        0.0                  True\n",
      "15                15        15.0         3.6052                 15.0                  3.5829        15.0        82.9974        0.0        0.0                  True\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GPU/CPU energy functions (same definition, different backend)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    \"\"\"CPU energy using NumPy (matches your calculate_energy_vectorized).\"\"\"\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    # keep integer math; cast at end\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "def energy_cupy(s_cp) -> float:\n",
    "    \"\"\"\n",
    "    GPU energy using CuPy.\n",
    "    Input: cupy array of shape (N,), dtype int8/int16/int32 recommended.\n",
    "    Output: Python float (synchronized).\n",
    "    \"\"\"\n",
    "    N = int(s_cp.shape[0])\n",
    "    e = cp.int64(0)\n",
    "    for k in range(1, N):\n",
    "        Ck = cp.sum(s_cp[:N-k] * s_cp[k:])\n",
    "        e += Ck * Ck\n",
    "    # synchronize and return host float\n",
    "    return float(e.get())\n",
    "\n",
    "def generate_population_gpu_seed_only(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Use GPU RNG to generate initial population, then transfer to CPU numpy arrays.\n",
    "    Output population is a list of np.ndarray (dtype int8) suitable for CPU MTS.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot use gpu_seed_only mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "\n",
    "    # Generate 0/1 then map to ±1, store compactly\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "\n",
    "    # Transfer once to CPU\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)  # shape (K,N), dtype int8\n",
    "\n",
    "    # Convert to list of 1D arrays (matches your code structure)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "# ============================================================\n",
    "# Wrappers: adapt your MTS to run with either energy backend\n",
    "#   (minimal surgical edits: pass energy_fn and array module)\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    \"\"\"In-place flip for numpy/cupy arrays.\"\"\"\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_backend(s0, energy_fn, xp, max_iter=None):\n",
    "    \"\"\"\n",
    "    Same logic as your tabu_search, but:\n",
    "      - uses in-place flips to reduce allocations\n",
    "      - uses energy_fn backend\n",
    "      - uses xp (np or cp) for array ops\n",
    "    Returns: best sequence (same type as input, numpy or cupy array)\n",
    "    \"\"\"\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_fn(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)  # tabu list small; keep on CPU\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        # Explore 1-flip neighborhood\n",
    "        for i in range(N):\n",
    "            # flip temporarily\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_fn(s)\n",
    "            flip_inplace(s, i)  # flip back\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # NOTE: Fix aspiration bug: tabu moves must still compete for \"best admissible\"\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            # Commit best move\n",
    "            flip_inplace(s, best_i)\n",
    "\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_backend(\n",
    "    N,\n",
    "    K,\n",
    "    G_max,\n",
    "    p_comb=0.9,\n",
    "    p_mut=None,\n",
    "    E_target=None,\n",
    "    use_optimal_target=True,\n",
    "    stop_at_target=True,\n",
    "    energy_fn=energy_numpy,\n",
    "    xp=np,\n",
    "    init_population=None,   # <---- ADD THIS\n",
    "):\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if use_optimal_target and (N in LABS_OPTIMAL) and (E_target is None):\n",
    "        E_target = LABS_OPTIMAL[N]\n",
    "\n",
    "    # -------------------------\n",
    "    # Initialization (new)\n",
    "    # -------------------------\n",
    "    if init_population is not None:\n",
    "        # ⚠️ assume caller provides list length K of arrays length N, already on correct device\n",
    "        population = init_population\n",
    "    else:\n",
    "        if xp is np:\n",
    "            population = [np.random.choice([-1, 1], size=N).astype(np.int8) for _ in range(K)]\n",
    "        else:\n",
    "            population = [cp.asarray(np.random.choice([-1, 1], size=N).astype(np.int8)) for _ in range(K)]\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_fn(s_best)\n",
    "\n",
    "    for ind in population[1:]:\n",
    "        E = energy_fn(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    for _ in range(G_max):\n",
    "        if stop_at_target and (E_target is not None) and (E_best <= E_target):\n",
    "            break\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = xp.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        child = tabu_search_backend(child, energy_fn=energy_fn, xp=xp)\n",
    "\n",
    "        E_child = energy_fn(child)\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "    return float(E_best), s_best\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark across N: CPU vs GPU\n",
    "# ============================================================\n",
    "\n",
    "def benchmark_cpu_vs_gpu(\n",
    "    N_list,\n",
    "    K=100,\n",
    "    G_max=500,\n",
    "    trials=1,\n",
    "    stop_at_target=False,   # IMPORTANT for fair runtime comparisons\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of dict rows (easy to convert to pandas).\n",
    "    Measures wall-clock runtime for full MTS run.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, None)\n",
    "\n",
    "        for t in range(trials):\n",
    "            # ---- CPU run\n",
    "            np.random.seed(seed + 1000*t + N)\n",
    "            random.seed(seed + 1000*t + N)\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            E_cpu, _ = memetic_tabu_search_backend(\n",
    "                N=N, K=K, G_max=G_max,\n",
    "                use_optimal_target=True,\n",
    "                stop_at_target=stop_at_target,\n",
    "                energy_fn=energy_numpy,\n",
    "                xp=np,\n",
    "            )\n",
    "            t1 = time.perf_counter()\n",
    "\n",
    "            row = {\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_energy\": E_cpu,\n",
    "                \"cpu_runtime_s\": t1 - t0,\n",
    "            }\n",
    "\n",
    "            # ---- GPU run (if available)\n",
    "            if HAS_CUPY:\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                # Warm-up (reduces first-call overhead)\n",
    "                _ = cp.asarray(np.array([1, -1], dtype=np.int8))\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _ = memetic_tabu_search_backend(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    use_optimal_target=True,\n",
    "                    stop_at_target=stop_at_target,\n",
    "                    energy_fn=energy_cupy,\n",
    "                    xp=cp,\n",
    "                )\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                row.update({\n",
    "                    \"gpu_energy\": E_gpu,\n",
    "                    \"gpu_runtime_s\": g1 - g0,\n",
    "                    \"cpu_gpu_energy_match\": (abs(E_cpu - E_gpu) < 1e-9),\n",
    "                })\n",
    "            else:\n",
    "                row.update({\n",
    "                    \"gpu_energy\": None,\n",
    "                    \"gpu_runtime_s\": None,\n",
    "                    \"cpu_gpu_energy_match\": None,\n",
    "                })\n",
    "            # ---- GPU seed-only run (GPU for population init only; rest CPU)\n",
    "            if HAS_CUPY:\n",
    "                np.random.seed(seed + 3000*t + N)        # CPU RNG for all decisions after init\n",
    "                random.seed(seed + 3000*t + N)\n",
    "\n",
    "                # Warm-up GPU once\n",
    "                _ = cp.asarray(np.array([1, -1], dtype=np.int8))\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "                # GPU generates initial population -> copied to CPU\n",
    "                pop_seed = generate_population_gpu_seed_only(\n",
    "                    N=N, K=K, seed=seed + 3000*t + N\n",
    "                )\n",
    "\n",
    "                s0 = time.perf_counter()\n",
    "                E_seedonly, _ = memetic_tabu_search_backend(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    use_optimal_target=True,\n",
    "                    stop_at_target=stop_at_target,\n",
    "                    energy_fn=energy_numpy,   # CPU energy\n",
    "                    xp=np,                    # CPU arrays for the algorithm\n",
    "                    init_population=pop_seed  # <-- only init comes from GPU\n",
    "                )\n",
    "                s1 = time.perf_counter()\n",
    "\n",
    "                row.update({\n",
    "                    \"gpu_seedonly_energy\": E_seedonly,\n",
    "                    \"gpu_seedonly_runtime_s\": s1 - s0,\n",
    "                })\n",
    "            else:\n",
    "                row.update({\n",
    "                    \"gpu_seedonly_energy\": None,\n",
    "                    \"gpu_seedonly_runtime_s\": None,\n",
    "                })\n",
    "\n",
    "            # gaps vs reference\n",
    "            if ref is not None and ref != 0:\n",
    "                row[\"cpu_gap_%\"] = 100.0 * (E_cpu - ref) / ref\n",
    "                if row[\"gpu_energy\"] is not None:\n",
    "                    row[\"gpu_gap_%\"] = 100.0 * (row[\"gpu_energy\"] - ref) / ref\n",
    "                else:\n",
    "                    row[\"gpu_gap_%\"] = None\n",
    "            else:\n",
    "                row[\"cpu_gap_%\"] = None\n",
    "                row[\"gpu_gap_%\"] = None\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    N_list = [10, 12, 15]\n",
    "\n",
    "    rows = benchmark_cpu_vs_gpu(\n",
    "        N_list,\n",
    "        K=100,\n",
    "        G_max=300,\n",
    "        trials=1,\n",
    "        stop_at_target=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Convert results into a clean table\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Keep only the most important benchmark columns\n",
    "    df = df[[\n",
    "        \"N\",\n",
    "        \"reference_energy\",\n",
    "        \"cpu_energy\",\n",
    "        \"cpu_runtime_s\",\n",
    "        \"gpu_seedonly_energy\",\n",
    "        \"gpu_seedonly_runtime_s\",\n",
    "        \"gpu_energy\",\n",
    "        \"gpu_runtime_s\",\n",
    "        \"cpu_gap_%\",\n",
    "        \"gpu_gap_%\",\n",
    "        \"cpu_gpu_energy_match\"\n",
    "    ]]\n",
    "\n",
    "\n",
    "\n",
    "    # Round numeric values for readability\n",
    "    df[\"cpu_runtime_s\"] = df[\"cpu_runtime_s\"].round(4)\n",
    "    df[\"gpu_runtime_s\"] = df[\"gpu_runtime_s\"].round(4)\n",
    "    df[\"gpu_seedonly_runtime_s\"] = df[\"gpu_seedonly_runtime_s\"].round(4)\n",
    "\n",
    "\n",
    "    df[\"cpu_gap_%\"] = df[\"cpu_gap_%\"].round(2)\n",
    "    df[\"gpu_gap_%\"] = df[\"gpu_gap_%\"].round(2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\" CPU vs GPU MTS Benchmark Results (LABS)\")\n",
    "    print(\"=\"*90)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"=\"*90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017d292-09e2-438e-abbc-2bb6aa4214e5",
   "metadata": {},
   "source": [
    "## Higher N test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaeb02f9-d506-48fa-a7d2-85c50c535fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing incremental results to:\n",
      "  highN_mts_cpu_vs_gpu_seedonly.csv\n",
      "  highN_mts_cpu_vs_gpu_seedonly.jsonl\n",
      "\n",
      "\n",
      "===== N=20 (ref=26) =====\n",
      "\n",
      "[RUN] N=20 trial=0 @ 2026-02-01 06:18:33\n",
      "[CPU] starting...\n",
      "[CPU] done. E=26 time=8.532s\n",
      "[LOG] wrote after CPU step\n",
      "[GPU-SEEDONLY] generating initial population on GPU...\n",
      "[GPU-SEEDONLY] starting CPU solve with GPU-seeded population...\n",
      "[GPU-SEEDONLY] done. E=26 time=8.626s\n",
      "[LOG] wrote after GPU-seed-only step\n",
      "\n",
      "===== N=25 (ref=36) =====\n",
      "\n",
      "[RUN] N=25 trial=0 @ 2026-02-01 06:18:51\n",
      "[CPU] starting...\n",
      "[CPU] done. E=36 time=15.928s\n",
      "[LOG] wrote after CPU step\n",
      "[GPU-SEEDONLY] generating initial population on GPU...\n",
      "[GPU-SEEDONLY] starting CPU solve with GPU-seeded population...\n",
      "[GPU-SEEDONLY] done. E=44 time=15.850s\n",
      "[LOG] wrote after GPU-seed-only step\n",
      "\n",
      "===== N=30 (ref=59) =====\n",
      "\n",
      "[RUN] N=30 trial=0 @ 2026-02-01 06:19:22\n",
      "[CPU] starting...\n",
      "[CPU] done. E=67 time=28.086s\n",
      "[LOG] wrote after CPU step\n",
      "[GPU-SEEDONLY] generating initial population on GPU...\n",
      "[GPU-SEEDONLY] starting CPU solve with GPU-seeded population...\n",
      "[GPU-SEEDONLY] done. E=59 time=28.171s\n",
      "[LOG] wrote after GPU-seed-only step\n",
      "\n",
      "[DONE] Benchmark loop finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Your LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GPU seed-only population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_gpu_seed_only(N: int, K: int, seed: int) -> list:\n",
    "    \"\"\"\n",
    "    Use GPU RNG to generate initial population on GPU, then transfer to CPU.\n",
    "    Returns list[np.ndarray] (dtype int8), length K.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run gpu_seed_only mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)  # one transfer\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Your MTS pieces (CPU-only execution)\n",
    "#   - Assumes you have: tabu_search_backend, memetic_tabu_search_backend\n",
    "#   - Here we include CPU versions only, matching your earlier backend\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_backend_cpu(s0, max_iter=None):\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration fixed: tabu moves still compete for best admissible\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int = 100,\n",
    "    G_max: int = 500,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float = None,\n",
    "    stop_at_target: bool = False,\n",
    "    init_population: list | None = None,\n",
    "):\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    E_target = LABS_OPTIMAL.get(N, None)\n",
    "\n",
    "    if init_population is not None:\n",
    "        population = init_population\n",
    "    else:\n",
    "        population = [np.random.choice([-1, 1], size=N).astype(np.int8) for _ in range(K)]\n",
    "\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    for g in range(G_max):\n",
    "        if stop_at_target and (E_target is not None) and (E_best <= E_target):\n",
    "            break\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        child = tabu_search_backend_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "    return float(E_best), s_best\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Crash-resilient logging helpers\n",
    "# ============================================================\n",
    "\n",
    "def append_jsonl(path: str, record: dict):\n",
    "    \"\"\"Append a JSON record to a .jsonl file (one record per line).\"\"\"\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "\n",
    "def append_csv(path: str, record: dict, header_order: list):\n",
    "    \"\"\"Append a row to CSV, creating header if file doesn't exist.\"\"\"\n",
    "    new_file = not os.path.exists(path)\n",
    "    line = \",\".join(str(record.get(k, \"\")) for k in header_order)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header_order) + \"\\n\")\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main benchmark (CPU vs GPU-seed-only)\n",
    "# ============================================================\n",
    "\n",
    "def run_benchmark_highN(\n",
    "    N_list=(20, 25, 30),\n",
    "    K=100,\n",
    "    G_max=300,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    out_prefix=\"highN_mts_benchmark\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs CPU baseline and GPU-seed-only initialization benchmark.\n",
    "    Logs after every run so partial progress is never lost.\n",
    "    \"\"\"\n",
    "    jsonl_path = out_prefix + \".jsonl\"\n",
    "    csv_path = out_prefix + \".csv\"\n",
    "\n",
    "    columns = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"reference_energy\",\n",
    "        \"cpu_energy\",\n",
    "        \"cpu_runtime_s\",\n",
    "        \"gpu_seedonly_energy\",\n",
    "        \"gpu_seedonly_runtime_s\",\n",
    "        \"cpu_gap_pct\",\n",
    "        \"gpu_seedonly_gap_pct\",\n",
    "        \"status_cpu\",\n",
    "        \"status_gpu_seedonly\",\n",
    "        \"error_cpu\",\n",
    "        \"error_gpu_seedonly\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing incremental results to:\\n  {csv_path}\\n  {jsonl_path}\\n\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, None)\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_energy\": \"\",\n",
    "                \"cpu_runtime_s\": \"\",\n",
    "                \"gpu_seedonly_energy\": \"\",\n",
    "                \"gpu_seedonly_runtime_s\": \"\",\n",
    "                \"cpu_gap_pct\": \"\",\n",
    "                \"gpu_seedonly_gap_pct\": \"\",\n",
    "                \"status_cpu\": \"NOT_RUN\",\n",
    "                \"status_gpu_seedonly\": \"NOT_RUN\",\n",
    "                \"error_cpu\": \"\",\n",
    "                \"error_gpu_seedonly\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU baseline\n",
    "            # -------------------------\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "                print(\"[CPU] starting...\")\n",
    "\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _ = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    stop_at_target=False,\n",
    "                    init_population=None\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"status_cpu\"] = \"OK\"\n",
    "\n",
    "                if ref is not None and ref != 0:\n",
    "                    record[\"cpu_gap_pct\"] = 100.0 * (E_cpu - ref) / ref\n",
    "\n",
    "                print(f\"[CPU] done. E={E_cpu:.0f} time={record['cpu_runtime_s']:.3f}s\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"status_cpu\"] = \"FAIL\"\n",
    "                record[\"error_cpu\"] = repr(e)\n",
    "                print(f\"[CPU] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Write partial record immediately after CPU attempt\n",
    "            append_jsonl(jsonl_path, record)\n",
    "            append_csv(csv_path, record, columns)\n",
    "            print(\"[LOG] wrote after CPU step\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU seed-only (population init on GPU, solve on CPU)\n",
    "            # -------------------------\n",
    "            if not HAS_CUPY:\n",
    "                record[\"status_gpu_seedonly\"] = \"SKIP_NO_CUPY\"\n",
    "                append_jsonl(jsonl_path, record)\n",
    "                append_csv(csv_path, record, columns)\n",
    "                print(\"[GPU-SEEDONLY] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # CPU RNG controls algorithmic decisions after initialization\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                # Warm up GPU once per trial\n",
    "                _ = cp.asarray(np.array([1, -1], dtype=np.int8))\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "                print(\"[GPU-SEEDONLY] generating initial population on GPU...\")\n",
    "                pop_seed = generate_population_gpu_seed_only(N=N, K=K, seed=seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDONLY] starting CPU solve with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_seed, _ = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    stop_at_target=False,\n",
    "                    init_population=pop_seed\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record[\"gpu_seedonly_energy\"] = float(E_seed)\n",
    "                record[\"gpu_seedonly_runtime_s\"] = float(g1 - g0)\n",
    "                record[\"status_gpu_seedonly\"] = \"OK\"\n",
    "\n",
    "                if ref is not None and ref != 0:\n",
    "                    record[\"gpu_seedonly_gap_pct\"] = 100.0 * (E_seed - ref) / ref\n",
    "\n",
    "                print(f\"[GPU-SEEDONLY] done. E={E_seed:.0f} time={record['gpu_seedonly_runtime_s']:.3f}s\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"status_gpu_seedonly\"] = \"FAIL\"\n",
    "                record[\"error_gpu_seedonly\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDONLY] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Write record again after GPU-seed-only attempt\n",
    "            append_jsonl(jsonl_path, record)\n",
    "            append_csv(csv_path, record, columns)\n",
    "            print(\"[LOG] wrote after GPU-seed-only step\")\n",
    "\n",
    "    print(\"\\n[DONE] Benchmark loop finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Conservative settings for crash-prone runs:\n",
    "    # Lower G_max first, then scale up once stable.\n",
    "    run_benchmark_highN(\n",
    "        N_list=(20, 25, 30),\n",
    "        K=100,\n",
    "        G_max=300,     # start lower to avoid crashing; increase later\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        out_prefix=\"highN_mts_cpu_vs_gpu_seedonly\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34420010-ccbb-4c37-ac30-332d3d46a19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing CSV incrementally to: mts_fullrun_cpu_vs_gpu_seedonly.csv\n",
      "\n",
      "===== N=20 (ref=26) =====\n",
      "\n",
      "[RUN] N=20 trial=0 @ 2026-02-01 06:31:08\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=34 elapsed=1.5s\n",
      "    [gen 100/200] best E=26 elapsed=3.0s\n",
      "    [gen 150/200] best E=26 elapsed=4.5s\n",
      "    [gen 200/200] best E=26 elapsed=5.9s\n",
      "[CPU-SEEDED] done. E=26 time=5.909s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=26 elapsed=1.5s\n",
      "    [gen 100/200] best E=26 elapsed=3.0s\n",
      "    [gen 150/200] best E=26 elapsed=4.5s\n",
      "    [gen 200/200] best E=26 elapsed=5.9s\n",
      "[GPU-SEEDED] done. E=26 time=5.891s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=25 (ref=36) =====\n",
      "\n",
      "[RUN] N=25 trial=0 @ 2026-02-01 06:31:20\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=44 elapsed=2.6s\n",
      "    [gen 100/200] best E=44 elapsed=5.4s\n",
      "    [gen 150/200] best E=36 elapsed=7.9s\n",
      "    [gen 200/200] best E=36 elapsed=10.6s\n",
      "[CPU-SEEDED] done. E=36 time=10.648s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=48 elapsed=2.6s\n",
      "    [gen 100/200] best E=48 elapsed=5.5s\n",
      "    [gen 150/200] best E=48 elapsed=8.0s\n",
      "    [gen 200/200] best E=48 elapsed=10.8s\n",
      "[GPU-SEEDED] done. E=48 time=10.776s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=30 (ref=59) =====\n",
      "\n",
      "[RUN] N=30 trial=0 @ 2026-02-01 06:31:41\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=75 elapsed=5.1s\n",
      "    [gen 100/200] best E=75 elapsed=9.3s\n",
      "    [gen 150/200] best E=75 elapsed=13.7s\n",
      "    [gen 200/200] best E=75 elapsed=18.0s\n",
      "[CPU-SEEDED] done. E=75 time=18.049s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=59 elapsed=5.1s\n",
      "    [gen 100/200] best E=59 elapsed=9.4s\n",
      "    [gen 150/200] best E=59 elapsed=13.8s\n",
      "    [gen 200/200] best E=59 elapsed=18.2s\n",
      "[GPU-SEEDED] done. E=59 time=18.220s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=35 (ref=73) =====\n",
      "\n",
      "[RUN] N=35 trial=0 @ 2026-02-01 06:32:18\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=97 elapsed=6.6s\n",
      "    [gen 100/200] best E=97 elapsed=14.3s\n",
      "    [gen 150/200] best E=97 elapsed=21.6s\n",
      "    [gen 200/200] best E=97 elapsed=29.3s\n",
      "[CPU-SEEDED] done. E=97 time=29.313s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=97 elapsed=6.6s\n",
      "    [gen 100/200] best E=97 elapsed=14.3s\n",
      "    [gen 150/200] best E=97 elapsed=21.7s\n",
      "    [gen 200/200] best E=97 elapsed=29.4s\n",
      "[GPU-SEEDED] done. E=97 time=29.440s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=40 (ref=108) =====\n",
      "\n",
      "[RUN] N=40 trial=0 @ 2026-02-01 06:33:16\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=152 elapsed=11.7s\n",
      "    [gen 100/200] best E=132 elapsed=23.1s\n",
      "    [gen 150/200] best E=132 elapsed=33.4s\n",
      "    [gen 200/200] best E=132 elapsed=44.1s\n",
      "[CPU-SEEDED] done. E=132 time=44.160s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=128 elapsed=11.7s\n",
      "    [gen 100/200] best E=128 elapsed=23.1s\n",
      "    [gen 150/200] best E=128 elapsed=33.4s\n",
      "    [gen 200/200] best E=128 elapsed=44.2s\n",
      "[GPU-SEEDED] done. E=128 time=44.203s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=45 (ref=118) =====\n",
      "\n",
      "[RUN] N=45 trial=0 @ 2026-02-01 06:34:45\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=190 elapsed=14.1s\n",
      "    [gen 100/200] best E=158 elapsed=31.9s\n",
      "    [gen 150/200] best E=158 elapsed=48.3s\n",
      "    [gen 200/200] best E=158 elapsed=63.2s\n",
      "[CPU-SEEDED] done. E=158 time=63.265s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=186 elapsed=14.2s\n",
      "    [gen 100/200] best E=186 elapsed=32.3s\n",
      "    [gen 150/200] best E=174 elapsed=49.0s\n",
      "    [gen 200/200] best E=174 elapsed=64.2s\n",
      "[GPU-SEEDED] done. E=174 time=64.217s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "[DONE] All requested N finished (or timed out).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_cpu(N: int, K: int) -> list[np.ndarray]:\n",
    "    \"\"\"CPU RNG population: list of K arrays shape (N,) with ±1 int8.\"\"\"\n",
    "    pop = np.random.choice([-1, 1], size=(K, N)).astype(np.int8)\n",
    "    return [pop[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "def generate_population_gpu_seedonly(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    GPU RNG population on GPU, then transfer ONCE to CPU.\n",
    "    Returns list of numpy arrays shape (N,), dtype int8.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run GPU-seeded mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Tabu + MTS (CPU)\n",
    "#   - same structure as your code, but with:\n",
    "#       * aspiration fix (best admissible tabu move competes)\n",
    "#       * optional timeout checks per generation\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_cpu(s0: np.ndarray, max_iter: int = None) -> np.ndarray:\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration: tabu moves only allowed if they beat global best,\n",
    "            # but must still be best among admissible candidates\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int,\n",
    "    G_max: int,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float | None = None,\n",
    "    init_population: list[np.ndarray] | None = None,\n",
    "    timeout_s: float | None = None,\n",
    "    print_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full CPU MTS.\n",
    "    Returns: (best_energy, best_sequence, generations_completed, status)\n",
    "      status ∈ {\"OK\", \"TIMEOUT\"}\n",
    "    \"\"\"\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if init_population is None:\n",
    "        population = generate_population_cpu(N, K)\n",
    "    else:\n",
    "        population = init_population\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for g in range(1, G_max + 1):\n",
    "        if timeout_s is not None and (time.perf_counter() - start) > timeout_s:\n",
    "            return float(E_best), s_best, g - 1, \"TIMEOUT\"\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        # mutation\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        # local search\n",
    "        child = tabu_search_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "        if print_every and (g % print_every == 0):\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"    [gen {g}/{G_max}] best E={E_best:.0f} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    return float(E_best), s_best, G_max, \"OK\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV logging (incremental, crash-safe)\n",
    "# ============================================================\n",
    "\n",
    "def append_csv(path: str, record: dict, header: list[str]):\n",
    "    new_file = not os.path.exists(path)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "        f.write(\",\".join(str(record.get(k, \"\")) for k in header) + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark runner\n",
    "# ============================================================\n",
    "\n",
    "def run_full_benchmark(\n",
    "    N_list=(20, 25, 30, 35, 40, 45),\n",
    "    K=100,\n",
    "    G_max=200,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    timeout_s=None,          # e.g. 600 for 10 minutes per run\n",
    "    out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\",\n",
    "):\n",
    "    header = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"K\",\n",
    "        \"G_max\",\n",
    "        \"timeout_s\",\n",
    "        \"reference_energy\",\n",
    "\n",
    "        \"cpu_seed_energy\",\n",
    "        \"cpu_seed_runtime_s\",\n",
    "        \"cpu_seed_gens\",\n",
    "        \"cpu_seed_status\",\n",
    "        \"cpu_seed_gap_pct\",\n",
    "        \"cpu_seed_error\",\n",
    "\n",
    "        \"gpu_seed_energy\",\n",
    "        \"gpu_seed_runtime_s\",\n",
    "        \"gpu_seed_gens\",\n",
    "        \"gpu_seed_status\",\n",
    "        \"gpu_seed_gap_pct\",\n",
    "        \"gpu_seed_error\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing CSV incrementally to: {out_csv}\")\n",
    "    if not HAS_CUPY:\n",
    "        print(\"[WARN] CuPy not available: GPU-seeded runs will be skipped.\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, \"\")\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            base_record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"K\": K,\n",
    "                \"G_max\": G_max,\n",
    "                \"timeout_s\": timeout_s if timeout_s is not None else \"\",\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_seed_energy\": \"\",\n",
    "                \"cpu_seed_runtime_s\": \"\",\n",
    "                \"cpu_seed_gens\": \"\",\n",
    "                \"cpu_seed_status\": \"NOT_RUN\",\n",
    "                \"cpu_seed_gap_pct\": \"\",\n",
    "                \"cpu_seed_error\": \"\",\n",
    "                \"gpu_seed_energy\": \"\",\n",
    "                \"gpu_seed_runtime_s\": \"\",\n",
    "                \"gpu_seed_gens\": \"\",\n",
    "                \"gpu_seed_status\": \"NOT_RUN\",\n",
    "                \"gpu_seed_gap_pct\": \"\",\n",
    "                \"gpu_seed_error\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU-seeded full run\n",
    "            # -------------------------\n",
    "            record = dict(base_record)\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "\n",
    "                print(\"[CPU-SEEDED] generating population on CPU + solving...\")\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _, gens_cpu, status_cpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=None,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_seed_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_seed_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"cpu_seed_gens\"] = gens_cpu\n",
    "                record[\"cpu_seed_status\"] = status_cpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record[\"cpu_seed_gap_pct\"] = 100.0 * (E_cpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[CPU-SEEDED] done. E={E_cpu:.0f} time={record['cpu_seed_runtime_s']:.3f}s status={status_cpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"cpu_seed_status\"] = \"FAIL\"\n",
    "                record[\"cpu_seed_error\"] = repr(e)\n",
    "                print(f\"[CPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after CPU step\n",
    "            append_csv(out_csv, record, header)\n",
    "            print(\"[LOG] wrote after CPU-seeded run\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU-seeded full run (seed-only GPU)\n",
    "            # -------------------------\n",
    "            record2 = dict(record)  # start from CPU record, then fill GPU columns\n",
    "            if not HAS_CUPY:\n",
    "                record2[\"gpu_seed_status\"] = \"SKIP_NO_CUPY\"\n",
    "                append_csv(out_csv, record2, header)\n",
    "                print(\"[GPU-SEEDED] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # IMPORTANT: reseed CPU RNG for the solver decisions\n",
    "                # (keeps GPU-seeded runs reproducible across repeated experiments)\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] generating population on GPU...\")\n",
    "                pop_gpu_seed = generate_population_gpu_seedonly(N=N, K=K, seed=seed + 3000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] solving on CPU with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _, gens_gpu, status_gpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=pop_gpu_seed,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record2[\"gpu_seed_energy\"] = float(E_gpu)\n",
    "                record2[\"gpu_seed_runtime_s\"] = float(g1 - g0)\n",
    "                record2[\"gpu_seed_gens\"] = gens_gpu\n",
    "                record2[\"gpu_seed_status\"] = status_gpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record2[\"gpu_seed_gap_pct\"] = 100.0 * (E_gpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[GPU-SEEDED] done. E={E_gpu:.0f} time={record2['gpu_seed_runtime_s']:.3f}s status={status_gpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record2[\"gpu_seed_status\"] = \"FAIL\"\n",
    "                record2[\"gpu_seed_error\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after GPU step\n",
    "            append_csv(out_csv, record2, header)\n",
    "            print(\"[LOG] wrote after GPU-seeded run\")\n",
    "\n",
    "    print(\"\\n[DONE] All requested N finished (or timed out).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suggested start: keep G_max modest; scale up once stable.\n",
    "    run_full_benchmark(\n",
    "        N_list=(20, 25, 30, 35, 40, 45),\n",
    "        K=100,\n",
    "        G_max=200,\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        timeout_s=900,  # 15 minutes per run; set None to disable\n",
    "        out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324619cb-9675-4a11-acfb-5e810e678d5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing CSV incrementally to: mts_fullrun_cpu_vs_gpu_seedonly_02.csv\n",
      "\n",
      "===== N=20 (ref=26) =====\n",
      "\n",
      "[RUN] N=20 trial=0 @ 2026-02-01 06:38:53\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=34 elapsed=1.5s\n",
      "    [gen 100/1000] best E=26 elapsed=3.0s\n",
      "    [gen 150/1000] best E=26 elapsed=4.5s\n",
      "    [gen 200/1000] best E=26 elapsed=5.9s\n",
      "    [gen 250/1000] best E=26 elapsed=7.3s\n",
      "    [gen 300/1000] best E=26 elapsed=8.5s\n",
      "    [gen 350/1000] best E=26 elapsed=9.8s\n",
      "    [gen 400/1000] best E=26 elapsed=11.4s\n",
      "    [gen 450/1000] best E=26 elapsed=12.6s\n",
      "    [gen 500/1000] best E=26 elapsed=14.0s\n",
      "    [gen 550/1000] best E=26 elapsed=15.4s\n",
      "    [gen 600/1000] best E=26 elapsed=16.9s\n",
      "    [gen 650/1000] best E=26 elapsed=18.4s\n",
      "    [gen 700/1000] best E=26 elapsed=20.0s\n",
      "    [gen 750/1000] best E=26 elapsed=21.2s\n",
      "    [gen 800/1000] best E=26 elapsed=22.8s\n",
      "    [gen 850/1000] best E=26 elapsed=24.2s\n",
      "    [gen 900/1000] best E=26 elapsed=25.5s\n",
      "    [gen 950/1000] best E=26 elapsed=27.0s\n",
      "    [gen 1000/1000] best E=26 elapsed=28.3s\n",
      "[CPU-SEEDED] done. E=26 time=28.320s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/1000] best E=26 elapsed=1.5s\n",
      "    [gen 100/1000] best E=26 elapsed=3.0s\n",
      "    [gen 150/1000] best E=26 elapsed=4.5s\n",
      "    [gen 200/1000] best E=26 elapsed=5.9s\n",
      "    [gen 250/1000] best E=26 elapsed=7.3s\n",
      "    [gen 300/1000] best E=26 elapsed=8.5s\n",
      "    [gen 350/1000] best E=26 elapsed=9.8s\n",
      "    [gen 400/1000] best E=26 elapsed=11.4s\n",
      "    [gen 450/1000] best E=26 elapsed=12.6s\n",
      "    [gen 500/1000] best E=26 elapsed=14.0s\n",
      "    [gen 550/1000] best E=26 elapsed=15.4s\n",
      "    [gen 600/1000] best E=26 elapsed=16.9s\n",
      "    [gen 650/1000] best E=26 elapsed=18.3s\n",
      "    [gen 700/1000] best E=26 elapsed=20.0s\n",
      "    [gen 750/1000] best E=26 elapsed=21.2s\n",
      "    [gen 800/1000] best E=26 elapsed=22.8s\n",
      "    [gen 850/1000] best E=26 elapsed=24.2s\n",
      "    [gen 900/1000] best E=26 elapsed=25.5s\n",
      "    [gen 950/1000] best E=26 elapsed=27.0s\n",
      "    [gen 1000/1000] best E=26 elapsed=28.3s\n",
      "[GPU-SEEDED] done. E=26 time=28.277s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=25 (ref=36) =====\n",
      "\n",
      "[RUN] N=25 trial=0 @ 2026-02-01 06:39:50\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=44 elapsed=2.6s\n",
      "    [gen 100/1000] best E=44 elapsed=5.4s\n",
      "    [gen 150/1000] best E=36 elapsed=7.9s\n",
      "    [gen 200/1000] best E=36 elapsed=10.6s\n",
      "    [gen 250/1000] best E=36 elapsed=13.0s\n",
      "    [gen 300/1000] best E=36 elapsed=15.7s\n",
      "    [gen 350/1000] best E=36 elapsed=18.4s\n",
      "    [gen 400/1000] best E=36 elapsed=21.0s\n",
      "    [gen 450/1000] best E=36 elapsed=23.7s\n",
      "    [gen 500/1000] best E=36 elapsed=26.3s\n",
      "    [gen 550/1000] best E=36 elapsed=28.9s\n",
      "    [gen 600/1000] best E=36 elapsed=31.7s\n",
      "    [gen 650/1000] best E=36 elapsed=34.7s\n",
      "    [gen 700/1000] best E=36 elapsed=37.4s\n",
      "    [gen 750/1000] best E=36 elapsed=39.9s\n",
      "    [gen 800/1000] best E=36 elapsed=42.9s\n",
      "    [gen 850/1000] best E=36 elapsed=45.4s\n",
      "    [gen 900/1000] best E=36 elapsed=47.8s\n",
      "    [gen 950/1000] best E=36 elapsed=50.7s\n",
      "    [gen 1000/1000] best E=36 elapsed=53.5s\n",
      "[CPU-SEEDED] done. E=36 time=53.536s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/1000] best E=48 elapsed=2.6s\n",
      "    [gen 100/1000] best E=48 elapsed=5.4s\n",
      "    [gen 150/1000] best E=48 elapsed=7.9s\n",
      "    [gen 200/1000] best E=48 elapsed=10.7s\n",
      "    [gen 250/1000] best E=48 elapsed=13.1s\n",
      "    [gen 300/1000] best E=44 elapsed=15.8s\n",
      "    [gen 350/1000] best E=44 elapsed=18.5s\n",
      "    [gen 400/1000] best E=44 elapsed=21.0s\n",
      "    [gen 450/1000] best E=44 elapsed=23.8s\n",
      "    [gen 500/1000] best E=44 elapsed=26.4s\n",
      "    [gen 550/1000] best E=36 elapsed=29.0s\n",
      "    [gen 600/1000] best E=36 elapsed=31.8s\n",
      "    [gen 650/1000] best E=36 elapsed=34.8s\n",
      "    [gen 700/1000] best E=36 elapsed=37.5s\n",
      "    [gen 750/1000] best E=36 elapsed=40.1s\n",
      "    [gen 800/1000] best E=36 elapsed=43.0s\n",
      "    [gen 850/1000] best E=36 elapsed=45.5s\n",
      "    [gen 900/1000] best E=36 elapsed=48.0s\n",
      "    [gen 950/1000] best E=36 elapsed=50.9s\n",
      "    [gen 1000/1000] best E=36 elapsed=53.7s\n",
      "[GPU-SEEDED] done. E=36 time=53.739s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=30 (ref=59) =====\n",
      "\n",
      "[RUN] N=30 trial=0 @ 2026-02-01 06:41:37\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=75 elapsed=5.1s\n",
      "    [gen 100/1000] best E=75 elapsed=9.3s\n",
      "    [gen 150/1000] best E=75 elapsed=13.8s\n",
      "    [gen 200/1000] best E=75 elapsed=18.1s\n",
      "    [gen 250/1000] best E=67 elapsed=22.9s\n",
      "    [gen 300/1000] best E=67 elapsed=28.1s\n",
      "    [gen 350/1000] best E=67 elapsed=32.6s\n",
      "    [gen 400/1000] best E=67 elapsed=37.6s\n",
      "    [gen 450/1000] best E=67 elapsed=42.5s\n",
      "    [gen 500/1000] best E=67 elapsed=47.4s\n",
      "    [gen 550/1000] best E=67 elapsed=52.6s\n",
      "    [gen 600/1000] best E=67 elapsed=57.5s\n",
      "    [gen 650/1000] best E=67 elapsed=62.6s\n",
      "    [gen 700/1000] best E=67 elapsed=66.5s\n",
      "    [gen 750/1000] best E=67 elapsed=71.6s\n",
      "    [gen 800/1000] best E=67 elapsed=76.0s\n",
      "    [gen 850/1000] best E=67 elapsed=81.0s\n",
      "    [gen 900/1000] best E=67 elapsed=85.4s\n",
      "    [gen 950/1000] best E=67 elapsed=89.4s\n",
      "    [gen 1000/1000] best E=67 elapsed=94.2s\n",
      "[CPU-SEEDED] done. E=67 time=94.239s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/1000] best E=59 elapsed=5.1s\n",
      "    [gen 100/1000] best E=59 elapsed=9.3s\n",
      "    [gen 150/1000] best E=59 elapsed=13.7s\n",
      "    [gen 200/1000] best E=59 elapsed=18.1s\n",
      "    [gen 250/1000] best E=59 elapsed=22.9s\n",
      "    [gen 300/1000] best E=59 elapsed=28.1s\n",
      "    [gen 350/1000] best E=59 elapsed=32.6s\n",
      "    [gen 400/1000] best E=59 elapsed=37.7s\n",
      "    [gen 450/1000] best E=59 elapsed=42.5s\n",
      "    [gen 500/1000] best E=59 elapsed=47.5s\n",
      "    [gen 550/1000] best E=59 elapsed=52.7s\n",
      "    [gen 600/1000] best E=59 elapsed=57.5s\n",
      "    [gen 650/1000] best E=59 elapsed=62.6s\n",
      "    [gen 700/1000] best E=59 elapsed=66.5s\n",
      "    [gen 750/1000] best E=59 elapsed=71.6s\n",
      "    [gen 800/1000] best E=59 elapsed=76.1s\n",
      "    [gen 850/1000] best E=59 elapsed=81.1s\n",
      "    [gen 900/1000] best E=59 elapsed=85.4s\n",
      "    [gen 950/1000] best E=59 elapsed=89.4s\n",
      "    [gen 1000/1000] best E=59 elapsed=94.3s\n",
      "[GPU-SEEDED] done. E=59 time=94.288s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=35 (ref=73) =====\n",
      "\n",
      "[RUN] N=35 trial=0 @ 2026-02-01 06:44:46\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=97 elapsed=6.6s\n",
      "    [gen 100/1000] best E=97 elapsed=14.1s\n",
      "    [gen 150/1000] best E=97 elapsed=21.5s\n",
      "    [gen 200/1000] best E=97 elapsed=29.1s\n",
      "    [gen 250/1000] best E=97 elapsed=36.1s\n",
      "    [gen 300/1000] best E=89 elapsed=43.4s\n",
      "    [gen 350/1000] best E=89 elapsed=50.9s\n",
      "    [gen 400/1000] best E=89 elapsed=57.9s\n",
      "    [gen 450/1000] best E=89 elapsed=65.5s\n",
      "    [gen 500/1000] best E=89 elapsed=73.5s\n",
      "    [gen 550/1000] best E=89 elapsed=81.1s\n",
      "    [gen 600/1000] best E=89 elapsed=89.7s\n",
      "    [gen 650/1000] best E=89 elapsed=96.9s\n",
      "    [gen 700/1000] best E=89 elapsed=104.3s\n",
      "    [gen 750/1000] best E=89 elapsed=112.5s\n",
      "    [gen 800/1000] best E=89 elapsed=120.4s\n",
      "    [gen 850/1000] best E=89 elapsed=127.9s\n",
      "    [gen 900/1000] best E=89 elapsed=136.4s\n",
      "    [gen 950/1000] best E=89 elapsed=145.1s\n",
      "    [gen 1000/1000] best E=89 elapsed=153.2s\n",
      "[CPU-SEEDED] done. E=89 time=153.174s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/1000] best E=97 elapsed=6.6s\n",
      "    [gen 100/1000] best E=97 elapsed=14.2s\n",
      "    [gen 150/1000] best E=97 elapsed=21.6s\n",
      "    [gen 200/1000] best E=97 elapsed=29.3s\n",
      "    [gen 250/1000] best E=97 elapsed=36.3s\n",
      "    [gen 300/1000] best E=97 elapsed=43.7s\n",
      "    [gen 350/1000] best E=97 elapsed=51.1s\n",
      "    [gen 400/1000] best E=97 elapsed=58.3s\n",
      "    [gen 450/1000] best E=97 elapsed=65.9s\n",
      "    [gen 500/1000] best E=97 elapsed=74.0s\n",
      "    [gen 550/1000] best E=97 elapsed=81.6s\n",
      "    [gen 600/1000] best E=97 elapsed=90.3s\n",
      "    [gen 650/1000] best E=97 elapsed=97.5s\n",
      "    [gen 700/1000] best E=97 elapsed=105.1s\n",
      "    [gen 750/1000] best E=97 elapsed=113.4s\n",
      "    [gen 800/1000] best E=89 elapsed=121.2s\n",
      "    [gen 850/1000] best E=89 elapsed=128.8s\n",
      "    [gen 900/1000] best E=89 elapsed=137.3s\n",
      "    [gen 950/1000] best E=89 elapsed=146.0s\n",
      "    [gen 1000/1000] best E=89 elapsed=154.1s\n",
      "[GPU-SEEDED] done. E=89 time=154.159s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=40 (ref=108) =====\n",
      "\n",
      "[RUN] N=40 trial=0 @ 2026-02-01 06:49:53\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=152 elapsed=11.6s\n",
      "    [gen 100/1000] best E=132 elapsed=22.9s\n",
      "    [gen 150/1000] best E=132 elapsed=33.2s\n",
      "    [gen 200/1000] best E=132 elapsed=43.9s\n",
      "    [gen 250/1000] best E=132 elapsed=56.4s\n",
      "    [gen 300/1000] best E=132 elapsed=67.4s\n",
      "    [gen 350/1000] best E=132 elapsed=79.1s\n",
      "    [gen 400/1000] best E=132 elapsed=90.2s\n",
      "    [gen 450/1000] best E=132 elapsed=100.8s\n",
      "    [gen 500/1000] best E=124 elapsed=112.0s\n",
      "    [gen 550/1000] best E=124 elapsed=122.1s\n",
      "    [gen 600/1000] best E=124 elapsed=132.2s\n",
      "    [gen 650/1000] best E=124 elapsed=142.9s\n",
      "    [gen 700/1000] best E=124 elapsed=153.9s\n",
      "    [gen 750/1000] best E=120 elapsed=164.9s\n",
      "    [gen 800/1000] best E=120 elapsed=177.0s\n",
      "    [gen 850/1000] best E=120 elapsed=187.4s\n",
      "    [gen 900/1000] best E=120 elapsed=199.2s\n",
      "    [gen 950/1000] best E=120 elapsed=210.6s\n",
      "    [gen 1000/1000] best E=120 elapsed=221.0s\n",
      "[CPU-SEEDED] done. E=120 time=220.992s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/1000] best E=128 elapsed=11.7s\n",
      "    [gen 100/1000] best E=128 elapsed=23.0s\n",
      "    [gen 150/1000] best E=128 elapsed=33.4s\n",
      "    [gen 200/1000] best E=128 elapsed=44.2s\n",
      "    [gen 250/1000] best E=128 elapsed=56.8s\n",
      "    [gen 300/1000] best E=128 elapsed=68.0s\n",
      "    [gen 350/1000] best E=128 elapsed=79.7s\n",
      "    [gen 400/1000] best E=128 elapsed=91.1s\n",
      "    [gen 450/1000] best E=128 elapsed=101.9s\n",
      "    [gen 500/1000] best E=128 elapsed=113.2s\n",
      "    [gen 550/1000] best E=128 elapsed=123.2s\n",
      "    [gen 600/1000] best E=128 elapsed=133.3s\n",
      "    [gen 650/1000] best E=128 elapsed=144.0s\n",
      "    [gen 700/1000] best E=128 elapsed=155.0s\n",
      "    [gen 750/1000] best E=128 elapsed=166.0s\n",
      "    [gen 800/1000] best E=128 elapsed=178.2s\n",
      "    [gen 850/1000] best E=128 elapsed=188.7s\n",
      "    [gen 900/1000] best E=128 elapsed=200.6s\n",
      "    [gen 950/1000] best E=128 elapsed=212.1s\n",
      "    [gen 1000/1000] best E=128 elapsed=222.5s\n",
      "[GPU-SEEDED] done. E=128 time=222.542s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=45 (ref=118) =====\n",
      "\n",
      "[RUN] N=45 trial=0 @ 2026-02-01 06:57:17\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=190 elapsed=14.0s\n",
      "    [gen 100/1000] best E=158 elapsed=31.8s\n",
      "    [gen 150/1000] best E=158 elapsed=48.2s\n",
      "    [gen 200/1000] best E=158 elapsed=63.0s\n",
      "    [gen 250/1000] best E=158 elapsed=77.7s\n",
      "    [gen 300/1000] best E=158 elapsed=92.6s\n",
      "    [gen 350/1000] best E=158 elapsed=108.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 369\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[DONE] All requested N finished (or timed out).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Suggested start: keep G_max modest; scale up once stable.\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     \u001b[43mrun_full_benchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mN_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mG_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 15 minutes per run; set None to disable\u001b[39;49;00m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmts_fullrun_cpu_vs_gpu_seedonly_02.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 289\u001b[0m, in \u001b[0;36mrun_full_benchmark\u001b[0;34m(N_list, K, G_max, trials, seed, timeout_s, out_csv)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[CPU-SEEDED] generating population on CPU + solving...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 289\u001b[0m E_cpu, _, gens_cpu, status_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mmemetic_tabu_search_cpu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mG_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_population\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    297\u001b[0m record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_seed_energy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(E_cpu)\n",
      "Cell \u001b[0;32mIn[15], line 180\u001b[0m, in \u001b[0;36mmemetic_tabu_search_cpu\u001b[0;34m(N, K, G_max, p_comb, p_mut, init_population, timeout_s, print_every)\u001b[0m\n\u001b[1;32m    177\u001b[0m         child[i] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# local search\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m child \u001b[38;5;241m=\u001b[39m \u001b[43mtabu_search_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m E_child \u001b[38;5;241m=\u001b[39m energy_numpy(child)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m E_child \u001b[38;5;241m<\u001b[39m E_best:\n",
      "Cell \u001b[0;32mIn[15], line 100\u001b[0m, in \u001b[0;36mtabu_search_cpu\u001b[0;34m(s0, max_iter)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m     99\u001b[0m     flip_inplace(s, i)\n\u001b[0;32m--> 100\u001b[0m     E_neighbor \u001b[38;5;241m=\u001b[39m \u001b[43menergy_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     flip_inplace(s, i)\n\u001b[1;32m    103\u001b[0m     is_tabu \u001b[38;5;241m=\u001b[39m tabu_list[i] \u001b[38;5;241m>\u001b[39m t\n",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m, in \u001b[0;36menergy_numpy\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     38\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N):\n\u001b[0;32m---> 40\u001b[0m     Ck \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     41\u001b[0m     e \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Ck \u001b[38;5;241m*\u001b[39m Ck\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(e)\n",
      "File \u001b[0;32m~/.qbraid/environments/fg2h/pyenv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:2425\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, _gentype):\n\u001b[1;32m   2418\u001b[0m     \u001b[38;5;66;03m# 2018-02-25, 1.15.0\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2420\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling np.sum(generator) is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse np.sum(np.fromiter(generator)) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe python sum builtin instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2423\u001b[0m     )\n\u001b[0;32m-> 2425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.qbraid/environments/fg2h/pyenv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:83\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_cpu(N: int, K: int) -> list[np.ndarray]:\n",
    "    \"\"\"CPU RNG population: list of K arrays shape (N,) with ±1 int8.\"\"\"\n",
    "    pop = np.random.choice([-1, 1], size=(K, N)).astype(np.int8)\n",
    "    return [pop[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "def generate_population_gpu_seedonly(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    GPU RNG population on GPU, then transfer ONCE to CPU.\n",
    "    Returns list of numpy arrays shape (N,), dtype int8.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run GPU-seeded mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Tabu + MTS (CPU)\n",
    "#   - same structure as your code, but with:\n",
    "#       * aspiration fix (best admissible tabu move competes)\n",
    "#       * optional timeout checks per generation\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_cpu(s0: np.ndarray, max_iter: int = None) -> np.ndarray:\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration: tabu moves only allowed if they beat global best,\n",
    "            # but must still be best among admissible candidates\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int,\n",
    "    G_max: int,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float | None = None,\n",
    "    init_population: list[np.ndarray] | None = None,\n",
    "    timeout_s: float | None = None,\n",
    "    print_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full CPU MTS.\n",
    "    Returns: (best_energy, best_sequence, generations_completed, status)\n",
    "      status ∈ {\"OK\", \"TIMEOUT\"}\n",
    "    \"\"\"\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if init_population is None:\n",
    "        population = generate_population_cpu(N, K)\n",
    "    else:\n",
    "        population = init_population\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for g in range(1, G_max + 1):\n",
    "        if timeout_s is not None and (time.perf_counter() - start) > timeout_s:\n",
    "            return float(E_best), s_best, g - 1, \"TIMEOUT\"\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        # mutation\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        # local search\n",
    "        child = tabu_search_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "        if print_every and (g % print_every == 0):\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"    [gen {g}/{G_max}] best E={E_best:.0f} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    return float(E_best), s_best, G_max, \"OK\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV logging (incremental, crash-safe)\n",
    "# ============================================================\n",
    "\n",
    "def append_csv(path: str, record: dict, header: list[str]):\n",
    "    new_file = not os.path.exists(path)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "        f.write(\",\".join(str(record.get(k, \"\")) for k in header) + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark runner\n",
    "# ============================================================\n",
    "\n",
    "def run_full_benchmark(\n",
    "    N_list=(20, 25, 30, 35, 40, 45, 50),\n",
    "    K=100,\n",
    "    G_max=200,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    timeout_s=None,          # e.g. 600 for 10 minutes per run\n",
    "    out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\",\n",
    "):\n",
    "    header = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"K\",\n",
    "        \"G_max\",\n",
    "        \"timeout_s\",\n",
    "        \"reference_energy\",\n",
    "\n",
    "        \"cpu_seed_energy\",\n",
    "        \"cpu_seed_runtime_s\",\n",
    "        \"cpu_seed_gens\",\n",
    "        \"cpu_seed_status\",\n",
    "        \"cpu_seed_gap_pct\",\n",
    "        \"cpu_seed_error\",\n",
    "\n",
    "        \"gpu_seed_energy\",\n",
    "        \"gpu_seed_runtime_s\",\n",
    "        \"gpu_seed_gens\",\n",
    "        \"gpu_seed_status\",\n",
    "        \"gpu_seed_gap_pct\",\n",
    "        \"gpu_seed_error\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing CSV incrementally to: {out_csv}\")\n",
    "    if not HAS_CUPY:\n",
    "        print(\"[WARN] CuPy not available: GPU-seeded runs will be skipped.\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, \"\")\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            base_record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"K\": K,\n",
    "                \"G_max\": G_max,\n",
    "                \"timeout_s\": timeout_s if timeout_s is not None else \"\",\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_seed_energy\": \"\",\n",
    "                \"cpu_seed_runtime_s\": \"\",\n",
    "                \"cpu_seed_gens\": \"\",\n",
    "                \"cpu_seed_status\": \"NOT_RUN\",\n",
    "                \"cpu_seed_gap_pct\": \"\",\n",
    "                \"cpu_seed_error\": \"\",\n",
    "                \"gpu_seed_energy\": \"\",\n",
    "                \"gpu_seed_runtime_s\": \"\",\n",
    "                \"gpu_seed_gens\": \"\",\n",
    "                \"gpu_seed_status\": \"NOT_RUN\",\n",
    "                \"gpu_seed_gap_pct\": \"\",\n",
    "                \"gpu_seed_error\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU-seeded full run\n",
    "            # -------------------------\n",
    "            record = dict(base_record)\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "\n",
    "                print(\"[CPU-SEEDED] generating population on CPU + solving...\")\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _, gens_cpu, status_cpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=None,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_seed_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_seed_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"cpu_seed_gens\"] = gens_cpu\n",
    "                record[\"cpu_seed_status\"] = status_cpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record[\"cpu_seed_gap_pct\"] = 100.0 * (E_cpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[CPU-SEEDED] done. E={E_cpu:.0f} time={record['cpu_seed_runtime_s']:.3f}s status={status_cpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"cpu_seed_status\"] = \"FAIL\"\n",
    "                record[\"cpu_seed_error\"] = repr(e)\n",
    "                print(f\"[CPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after CPU step\n",
    "            append_csv(out_csv, record, header)\n",
    "            print(\"[LOG] wrote after CPU-seeded run\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU-seeded full run (seed-only GPU)\n",
    "            # -------------------------\n",
    "            record2 = dict(record)  # start from CPU record, then fill GPU columns\n",
    "            if not HAS_CUPY:\n",
    "                record2[\"gpu_seed_status\"] = \"SKIP_NO_CUPY\"\n",
    "                append_csv(out_csv, record2, header)\n",
    "                print(\"[GPU-SEEDED] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # IMPORTANT: reseed CPU RNG for the solver decisions\n",
    "                # (keeps GPU-seeded runs reproducible across repeated experiments)\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] generating population on GPU...\")\n",
    "                pop_gpu_seed = generate_population_gpu_seedonly(N=N, K=K, seed=seed + 3000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] solving on CPU with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _, gens_gpu, status_gpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=pop_gpu_seed,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record2[\"gpu_seed_energy\"] = float(E_gpu)\n",
    "                record2[\"gpu_seed_runtime_s\"] = float(g1 - g0)\n",
    "                record2[\"gpu_seed_gens\"] = gens_gpu\n",
    "                record2[\"gpu_seed_status\"] = status_gpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record2[\"gpu_seed_gap_pct\"] = 100.0 * (E_gpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[GPU-SEEDED] done. E={E_gpu:.0f} time={record2['gpu_seed_runtime_s']:.3f}s status={status_gpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record2[\"gpu_seed_status\"] = \"FAIL\"\n",
    "                record2[\"gpu_seed_error\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after GPU step\n",
    "            append_csv(out_csv, record2, header)\n",
    "            print(\"[LOG] wrote after GPU-seeded run\")\n",
    "\n",
    "    print(\"\\n[DONE] All requested N finished (or timed out).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suggested start: keep G_max modest; scale up once stable.\n",
    "    run_full_benchmark(\n",
    "        N_list=(20, 25, 30, 35, 40, 45, 50),\n",
    "        K=100,\n",
    "        G_max=1000,\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        timeout_s=900,  # 15 minutes per run; set None to disable\n",
    "        out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly_02.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deaffa73-e5fd-42fd-887a-2559776e3b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing CSV incrementally to: mts_fullrun_cpu_vs_gpu_seedonly_03.csv\n",
      "\n",
      "===== N=20 (ref=26) =====\n",
      "\n",
      "[RUN] N=20 trial=0 @ 2026-02-01 07:00:38\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=34 elapsed=1.5s\n",
      "    [gen 100/300] best E=26 elapsed=3.0s\n",
      "    [gen 150/300] best E=26 elapsed=4.5s\n",
      "    [gen 200/300] best E=26 elapsed=5.9s\n",
      "    [gen 250/300] best E=26 elapsed=7.3s\n",
      "    [gen 300/300] best E=26 elapsed=8.5s\n",
      "[CPU-SEEDED] done. E=26 time=8.519s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=26 elapsed=1.5s\n",
      "    [gen 100/300] best E=26 elapsed=3.0s\n",
      "    [gen 150/300] best E=26 elapsed=4.5s\n",
      "    [gen 200/300] best E=26 elapsed=5.9s\n",
      "    [gen 250/300] best E=26 elapsed=7.3s\n",
      "    [gen 300/300] best E=26 elapsed=8.6s\n",
      "[GPU-SEEDED] done. E=26 time=8.574s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=22 (ref=39) =====\n",
      "\n",
      "[RUN] N=22 trial=0 @ 2026-02-01 07:00:55\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=39 elapsed=1.9s\n",
      "    [gen 100/300] best E=39 elapsed=3.9s\n",
      "    [gen 150/300] best E=39 elapsed=5.7s\n",
      "    [gen 200/300] best E=39 elapsed=7.6s\n",
      "    [gen 250/300] best E=39 elapsed=9.5s\n",
      "    [gen 300/300] best E=39 elapsed=11.4s\n",
      "[CPU-SEEDED] done. E=39 time=11.458s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=39 elapsed=1.9s\n",
      "    [gen 100/300] best E=39 elapsed=3.9s\n",
      "    [gen 150/300] best E=39 elapsed=5.7s\n",
      "    [gen 200/300] best E=39 elapsed=7.7s\n",
      "    [gen 250/300] best E=39 elapsed=9.5s\n",
      "    [gen 300/300] best E=39 elapsed=11.5s\n",
      "[GPU-SEEDED] done. E=39 time=11.501s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=24 (ref=36) =====\n",
      "\n",
      "[RUN] N=24 trial=0 @ 2026-02-01 07:01:18\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=52 elapsed=2.2s\n",
      "    [gen 100/300] best E=52 elapsed=4.6s\n",
      "    [gen 150/300] best E=52 elapsed=7.0s\n",
      "    [gen 200/300] best E=48 elapsed=9.3s\n",
      "    [gen 250/300] best E=36 elapsed=11.6s\n",
      "    [gen 300/300] best E=36 elapsed=13.6s\n",
      "[CPU-SEEDED] done. E=36 time=13.585s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=52 elapsed=2.3s\n",
      "    [gen 100/300] best E=36 elapsed=4.6s\n",
      "    [gen 150/300] best E=36 elapsed=7.0s\n",
      "    [gen 200/300] best E=36 elapsed=9.4s\n",
      "    [gen 250/300] best E=36 elapsed=11.7s\n",
      "    [gen 300/300] best E=36 elapsed=13.6s\n",
      "[GPU-SEEDED] done. E=36 time=13.649s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=26 (ref=45) =====\n",
      "\n",
      "[RUN] N=26 trial=0 @ 2026-02-01 07:01:45\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=45 elapsed=3.4s\n",
      "    [gen 100/300] best E=45 elapsed=6.3s\n",
      "    [gen 150/300] best E=45 elapsed=9.3s\n",
      "    [gen 200/300] best E=45 elapsed=12.2s\n",
      "    [gen 250/300] best E=45 elapsed=15.5s\n",
      "    [gen 300/300] best E=45 elapsed=18.1s\n",
      "[CPU-SEEDED] done. E=45 time=18.151s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=45 elapsed=3.4s\n",
      "    [gen 100/300] best E=45 elapsed=6.3s\n",
      "    [gen 150/300] best E=45 elapsed=9.4s\n",
      "    [gen 200/300] best E=45 elapsed=12.3s\n",
      "    [gen 250/300] best E=45 elapsed=15.5s\n",
      "    [gen 300/300] best E=45 elapsed=18.2s\n",
      "[GPU-SEEDED] done. E=45 time=18.211s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=28 (ref=50) =====\n",
      "\n",
      "[RUN] N=28 trial=0 @ 2026-02-01 07:02:22\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=70 elapsed=3.9s\n",
      "    [gen 100/300] best E=70 elapsed=7.6s\n",
      "    [gen 150/300] best E=70 elapsed=11.2s\n",
      "    [gen 200/300] best E=62 elapsed=14.8s\n",
      "    [gen 250/300] best E=62 elapsed=18.4s\n",
      "    [gen 300/300] best E=62 elapsed=22.1s\n",
      "[CPU-SEEDED] done. E=62 time=22.129s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=50 elapsed=3.9s\n",
      "    [gen 100/300] best E=50 elapsed=7.6s\n",
      "    [gen 150/300] best E=50 elapsed=11.3s\n",
      "    [gen 200/300] best E=50 elapsed=14.9s\n",
      "    [gen 250/300] best E=50 elapsed=18.5s\n",
      "    [gen 300/300] best E=50 elapsed=22.2s\n",
      "[GPU-SEEDED] done. E=50 time=22.254s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=30 (ref=59) =====\n",
      "\n",
      "[RUN] N=30 trial=0 @ 2026-02-01 07:03:06\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=75 elapsed=5.1s\n",
      "    [gen 100/300] best E=75 elapsed=9.3s\n",
      "    [gen 150/300] best E=75 elapsed=13.7s\n",
      "    [gen 200/300] best E=75 elapsed=18.1s\n",
      "    [gen 250/300] best E=67 elapsed=22.9s\n",
      "    [gen 300/300] best E=67 elapsed=28.1s\n",
      "[CPU-SEEDED] done. E=67 time=28.137s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=59 elapsed=5.1s\n",
      "    [gen 100/300] best E=59 elapsed=9.3s\n",
      "    [gen 150/300] best E=59 elapsed=13.8s\n",
      "    [gen 200/300] best E=59 elapsed=18.2s\n",
      "    [gen 250/300] best E=59 elapsed=23.1s\n",
      "    [gen 300/300] best E=59 elapsed=28.3s\n",
      "[GPU-SEEDED] done. E=59 time=28.323s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=32 (ref=64) =====\n",
      "\n",
      "[RUN] N=32 trial=0 @ 2026-02-01 07:04:03\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=92 elapsed=6.0s\n",
      "    [gen 100/300] best E=92 elapsed=12.0s\n",
      "    [gen 150/300] best E=80 elapsed=17.5s\n",
      "    [gen 200/300] best E=80 elapsed=23.1s\n",
      "    [gen 250/300] best E=80 elapsed=29.3s\n",
      "    [gen 300/300] best E=80 elapsed=34.6s\n",
      "[CPU-SEEDED] done. E=80 time=34.649s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=80 elapsed=6.1s\n",
      "    [gen 100/300] best E=80 elapsed=12.1s\n",
      "    [gen 150/300] best E=80 elapsed=17.6s\n",
      "    [gen 200/300] best E=80 elapsed=23.3s\n",
      "    [gen 250/300] best E=76 elapsed=29.5s\n",
      "    [gen 300/300] best E=76 elapsed=34.9s\n",
      "[GPU-SEEDED] done. E=76 time=34.897s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=34 (ref=65) =====\n",
      "\n",
      "[RUN] N=34 trial=0 @ 2026-02-01 07:05:12\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/300] best E=97 elapsed=7.1s\n",
      "    [gen 100/300] best E=97 elapsed=13.3s\n",
      "    [gen 150/300] best E=97 elapsed=20.3s\n",
      "    [gen 200/300] best E=97 elapsed=26.7s\n",
      "    [gen 250/300] best E=97 elapsed=33.6s\n",
      "    [gen 300/300] best E=81 elapsed=40.5s\n",
      "[CPU-SEEDED] done. E=81 time=40.467s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/300] best E=97 elapsed=7.1s\n",
      "    [gen 100/300] best E=97 elapsed=13.3s\n",
      "    [gen 150/300] best E=97 elapsed=20.3s\n",
      "    [gen 200/300] best E=89 elapsed=26.8s\n",
      "    [gen 250/300] best E=89 elapsed=33.6s\n",
      "    [gen 300/300] best E=89 elapsed=40.6s\n",
      "[GPU-SEEDED] done. E=89 time=40.597s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "[DONE] All requested N finished (or timed out).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_cpu(N: int, K: int) -> list[np.ndarray]:\n",
    "    \"\"\"CPU RNG population: list of K arrays shape (N,) with ±1 int8.\"\"\"\n",
    "    pop = np.random.choice([-1, 1], size=(K, N)).astype(np.int8)\n",
    "    return [pop[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "def generate_population_gpu_seedonly(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    GPU RNG population on GPU, then transfer ONCE to CPU.\n",
    "    Returns list of numpy arrays shape (N,), dtype int8.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run GPU-seeded mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Tabu + MTS (CPU)\n",
    "#   - same structure as your code, but with:\n",
    "#       * aspiration fix (best admissible tabu move competes)\n",
    "#       * optional timeout checks per generation\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_cpu(s0: np.ndarray, max_iter: int = None) -> np.ndarray:\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration: tabu moves only allowed if they beat global best,\n",
    "            # but must still be best among admissible candidates\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int,\n",
    "    G_max: int,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float | None = None,\n",
    "    init_population: list[np.ndarray] | None = None,\n",
    "    timeout_s: float | None = None,\n",
    "    print_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full CPU MTS.\n",
    "    Returns: (best_energy, best_sequence, generations_completed, status)\n",
    "      status ∈ {\"OK\", \"TIMEOUT\"}\n",
    "    \"\"\"\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if init_population is None:\n",
    "        population = generate_population_cpu(N, K)\n",
    "    else:\n",
    "        population = init_population\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for g in range(1, G_max + 1):\n",
    "        if timeout_s is not None and (time.perf_counter() - start) > timeout_s:\n",
    "            return float(E_best), s_best, g - 1, \"TIMEOUT\"\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        # mutation\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        # local search\n",
    "        child = tabu_search_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "        if print_every and (g % print_every == 0):\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"    [gen {g}/{G_max}] best E={E_best:.0f} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    return float(E_best), s_best, G_max, \"OK\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV logging (incremental, crash-safe)\n",
    "# ============================================================\n",
    "\n",
    "def append_csv(path: str, record: dict, header: list[str]):\n",
    "    new_file = not os.path.exists(path)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "        f.write(\",\".join(str(record.get(k, \"\")) for k in header) + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark runner\n",
    "# ============================================================\n",
    "\n",
    "def run_full_benchmark(\n",
    "    N_list=(20, 25, 30, 35, 40, 45, 50),\n",
    "    K=100,\n",
    "    G_max=200,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    timeout_s=None,          # e.g. 600 for 10 minutes per run\n",
    "    out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\",\n",
    "):\n",
    "    header = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"K\",\n",
    "        \"G_max\",\n",
    "        \"timeout_s\",\n",
    "        \"reference_energy\",\n",
    "\n",
    "        \"cpu_seed_energy\",\n",
    "        \"cpu_seed_runtime_s\",\n",
    "        \"cpu_seed_gens\",\n",
    "        \"cpu_seed_status\",\n",
    "        \"cpu_seed_gap_pct\",\n",
    "        \"cpu_seed_error\",\n",
    "\n",
    "        \"gpu_seed_energy\",\n",
    "        \"gpu_seed_runtime_s\",\n",
    "        \"gpu_seed_gens\",\n",
    "        \"gpu_seed_status\",\n",
    "        \"gpu_seed_gap_pct\",\n",
    "        \"gpu_seed_error\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing CSV incrementally to: {out_csv}\")\n",
    "    if not HAS_CUPY:\n",
    "        print(\"[WARN] CuPy not available: GPU-seeded runs will be skipped.\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, \"\")\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            base_record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"K\": K,\n",
    "                \"G_max\": G_max,\n",
    "                \"timeout_s\": timeout_s if timeout_s is not None else \"\",\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_seed_energy\": \"\",\n",
    "                \"cpu_seed_runtime_s\": \"\",\n",
    "                \"cpu_seed_gens\": \"\",\n",
    "                \"cpu_seed_status\": \"NOT_RUN\",\n",
    "                \"cpu_seed_gap_pct\": \"\",\n",
    "                \"cpu_seed_error\": \"\",\n",
    "                \"gpu_seed_energy\": \"\",\n",
    "                \"gpu_seed_runtime_s\": \"\",\n",
    "                \"gpu_seed_gens\": \"\",\n",
    "                \"gpu_seed_status\": \"NOT_RUN\",\n",
    "                \"gpu_seed_gap_pct\": \"\",\n",
    "                \"gpu_seed_error\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU-seeded full run\n",
    "            # -------------------------\n",
    "            record = dict(base_record)\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "\n",
    "                print(\"[CPU-SEEDED] generating population on CPU + solving...\")\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _, gens_cpu, status_cpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=None,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_seed_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_seed_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"cpu_seed_gens\"] = gens_cpu\n",
    "                record[\"cpu_seed_status\"] = status_cpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record[\"cpu_seed_gap_pct\"] = 100.0 * (E_cpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[CPU-SEEDED] done. E={E_cpu:.0f} time={record['cpu_seed_runtime_s']:.3f}s status={status_cpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"cpu_seed_status\"] = \"FAIL\"\n",
    "                record[\"cpu_seed_error\"] = repr(e)\n",
    "                print(f\"[CPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after CPU step\n",
    "            append_csv(out_csv, record, header)\n",
    "            print(\"[LOG] wrote after CPU-seeded run\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU-seeded full run (seed-only GPU)\n",
    "            # -------------------------\n",
    "            record2 = dict(record)  # start from CPU record, then fill GPU columns\n",
    "            if not HAS_CUPY:\n",
    "                record2[\"gpu_seed_status\"] = \"SKIP_NO_CUPY\"\n",
    "                append_csv(out_csv, record2, header)\n",
    "                print(\"[GPU-SEEDED] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # IMPORTANT: reseed CPU RNG for the solver decisions\n",
    "                # (keeps GPU-seeded runs reproducible across repeated experiments)\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] generating population on GPU...\")\n",
    "                pop_gpu_seed = generate_population_gpu_seedonly(N=N, K=K, seed=seed + 3000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] solving on CPU with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _, gens_gpu, status_gpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=pop_gpu_seed,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record2[\"gpu_seed_energy\"] = float(E_gpu)\n",
    "                record2[\"gpu_seed_runtime_s\"] = float(g1 - g0)\n",
    "                record2[\"gpu_seed_gens\"] = gens_gpu\n",
    "                record2[\"gpu_seed_status\"] = status_gpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record2[\"gpu_seed_gap_pct\"] = 100.0 * (E_gpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[GPU-SEEDED] done. E={E_gpu:.0f} time={record2['gpu_seed_runtime_s']:.3f}s status={status_gpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record2[\"gpu_seed_status\"] = \"FAIL\"\n",
    "                record2[\"gpu_seed_error\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after GPU step\n",
    "            append_csv(out_csv, record2, header)\n",
    "            print(\"[LOG] wrote after GPU-seeded run\")\n",
    "\n",
    "    print(\"\\n[DONE] All requested N finished (or timed out).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suggested start: keep G_max modest; scale up once stable.\n",
    "    run_full_benchmark(\n",
    "        N_list=(20, 22, 24, 26, 28, 30, 32, 34),\n",
    "        K=100,\n",
    "        G_max=300,\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        timeout_s=900,  # 15 minutes per run; set None to disable\n",
    "        out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly_03.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440d236a-0990-4b34-817f-5622f37c14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing CSV incrementally to: mts_fullrun_cpu_vs_gpu_seedonly_04.csv\n",
      "\n",
      "===== N=20 (ref=26) =====\n",
      "\n",
      "[RUN] N=20 trial=0 @ 2026-02-01 07:31:45\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=34 elapsed=1.5s\n",
      "    [gen 100/200] best E=26 elapsed=3.0s\n",
      "    [gen 150/200] best E=26 elapsed=4.5s\n",
      "    [gen 200/200] best E=26 elapsed=5.9s\n",
      "[CPU-SEEDED] done. E=26 time=5.921s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=26 elapsed=1.5s\n",
      "    [gen 100/200] best E=26 elapsed=3.1s\n",
      "    [gen 150/200] best E=26 elapsed=4.5s\n",
      "    [gen 200/200] best E=26 elapsed=6.0s\n",
      "[GPU-SEEDED] done. E=26 time=5.976s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=22 (ref=39) =====\n",
      "\n",
      "[RUN] N=22 trial=0 @ 2026-02-01 07:32:02\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=39 elapsed=2.0s\n",
      "    [gen 100/200] best E=39 elapsed=4.0s\n",
      "    [gen 150/200] best E=39 elapsed=5.7s\n",
      "    [gen 200/200] best E=39 elapsed=7.8s\n",
      "[CPU-SEEDED] done. E=39 time=7.761s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=39 elapsed=1.9s\n",
      "    [gen 100/200] best E=39 elapsed=3.9s\n",
      "    [gen 150/200] best E=39 elapsed=5.7s\n",
      "    [gen 200/200] best E=39 elapsed=7.7s\n",
      "[GPU-SEEDED] done. E=39 time=7.750s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=24 (ref=36) =====\n",
      "\n",
      "[RUN] N=24 trial=0 @ 2026-02-01 07:32:18\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=52 elapsed=2.2s\n",
      "    [gen 100/200] best E=52 elapsed=4.6s\n",
      "    [gen 150/200] best E=52 elapsed=7.1s\n",
      "    [gen 200/200] best E=48 elapsed=9.4s\n",
      "[CPU-SEEDED] done. E=48 time=9.415s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=52 elapsed=2.2s\n",
      "    [gen 100/200] best E=36 elapsed=4.6s\n",
      "    [gen 150/200] best E=36 elapsed=7.0s\n",
      "    [gen 200/200] best E=36 elapsed=9.4s\n",
      "[GPU-SEEDED] done. E=36 time=9.370s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=26 (ref=45) =====\n",
      "\n",
      "[RUN] N=26 trial=0 @ 2026-02-01 07:32:36\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=45 elapsed=3.4s\n",
      "    [gen 100/200] best E=45 elapsed=6.3s\n",
      "    [gen 150/200] best E=45 elapsed=9.3s\n",
      "    [gen 200/200] best E=45 elapsed=12.2s\n",
      "[CPU-SEEDED] done. E=45 time=12.238s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=45 elapsed=3.4s\n",
      "    [gen 100/200] best E=45 elapsed=6.3s\n",
      "    [gen 150/200] best E=45 elapsed=9.4s\n",
      "    [gen 200/200] best E=45 elapsed=12.4s\n",
      "[GPU-SEEDED] done. E=45 time=12.366s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=28 (ref=50) =====\n",
      "\n",
      "[RUN] N=28 trial=0 @ 2026-02-01 07:33:01\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=70 elapsed=4.0s\n",
      "    [gen 100/200] best E=70 elapsed=7.7s\n",
      "    [gen 150/200] best E=70 elapsed=11.4s\n",
      "    [gen 200/200] best E=62 elapsed=15.0s\n",
      "[CPU-SEEDED] done. E=62 time=15.047s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=50 elapsed=3.9s\n",
      "    [gen 100/200] best E=50 elapsed=7.6s\n",
      "    [gen 150/200] best E=50 elapsed=11.3s\n",
      "    [gen 200/200] best E=50 elapsed=14.9s\n",
      "[GPU-SEEDED] done. E=50 time=14.949s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=30 (ref=59) =====\n",
      "\n",
      "[RUN] N=30 trial=0 @ 2026-02-01 07:33:31\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=75 elapsed=5.2s\n",
      "    [gen 100/200] best E=75 elapsed=9.5s\n",
      "    [gen 150/200] best E=75 elapsed=14.0s\n",
      "    [gen 200/200] best E=75 elapsed=18.4s\n",
      "[CPU-SEEDED] done. E=75 time=18.374s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=59 elapsed=5.2s\n",
      "    [gen 100/200] best E=59 elapsed=9.4s\n",
      "    [gen 150/200] best E=59 elapsed=14.0s\n",
      "    [gen 200/200] best E=59 elapsed=18.4s\n",
      "[GPU-SEEDED] done. E=59 time=18.378s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=32 (ref=64) =====\n",
      "\n",
      "[RUN] N=32 trial=0 @ 2026-02-01 07:34:08\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=92 elapsed=6.2s\n",
      "    [gen 100/200] best E=92 elapsed=12.3s\n",
      "    [gen 150/200] best E=80 elapsed=17.8s\n",
      "    [gen 200/200] best E=80 elapsed=23.5s\n",
      "[CPU-SEEDED] done. E=80 time=23.518s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=80 elapsed=6.2s\n",
      "    [gen 100/200] best E=80 elapsed=12.2s\n",
      "    [gen 150/200] best E=80 elapsed=17.7s\n",
      "    [gen 200/200] best E=80 elapsed=23.4s\n",
      "[GPU-SEEDED] done. E=80 time=23.450s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=34 (ref=65) =====\n",
      "\n",
      "[RUN] N=34 trial=0 @ 2026-02-01 07:34:55\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=97 elapsed=7.2s\n",
      "    [gen 100/200] best E=97 elapsed=13.4s\n",
      "    [gen 150/200] best E=97 elapsed=20.5s\n",
      "    [gen 200/200] best E=97 elapsed=26.8s\n",
      "[CPU-SEEDED] done. E=97 time=26.866s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=97 elapsed=7.2s\n",
      "    [gen 100/200] best E=97 elapsed=13.4s\n",
      "    [gen 150/200] best E=97 elapsed=20.5s\n",
      "    [gen 200/200] best E=89 elapsed=27.0s\n",
      "[GPU-SEEDED] done. E=89 time=26.989s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "[DONE] All requested N finished (or timed out).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_cpu(N: int, K: int) -> list[np.ndarray]:\n",
    "    \"\"\"CPU RNG population: list of K arrays shape (N,) with ±1 int8.\"\"\"\n",
    "    pop = np.random.choice([-1, 1], size=(K, N)).astype(np.int8)\n",
    "    return [pop[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "def generate_population_gpu_seedonly(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    GPU RNG population on GPU, then transfer ONCE to CPU.\n",
    "    Returns list of numpy arrays shape (N,), dtype int8.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run GPU-seeded mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Tabu + MTS (CPU)\n",
    "#   - same structure as your code, but with:\n",
    "#       * aspiration fix (best admissible tabu move competes)\n",
    "#       * optional timeout checks per generation\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_cpu(s0: np.ndarray, max_iter: int = None) -> np.ndarray:\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration: tabu moves only allowed if they beat global best,\n",
    "            # but must still be best among admissible candidates\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int,\n",
    "    G_max: int,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float | None = None,\n",
    "    init_population: list[np.ndarray] | None = None,\n",
    "    timeout_s: float | None = None,\n",
    "    print_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full CPU MTS.\n",
    "    Returns: (best_energy, best_sequence, generations_completed, status)\n",
    "      status ∈ {\"OK\", \"TIMEOUT\"}\n",
    "    \"\"\"\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if init_population is None:\n",
    "        population = generate_population_cpu(N, K)\n",
    "    else:\n",
    "        population = init_population\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for g in range(1, G_max + 1):\n",
    "        if timeout_s is not None and (time.perf_counter() - start) > timeout_s:\n",
    "            return float(E_best), s_best, g - 1, \"TIMEOUT\"\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        # mutation\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        # local search\n",
    "        child = tabu_search_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "        if print_every and (g % print_every == 0):\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"    [gen {g}/{G_max}] best E={E_best:.0f} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    return float(E_best), s_best, G_max, \"OK\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV logging (incremental, crash-safe)\n",
    "# ============================================================\n",
    "\n",
    "def append_csv(path: str, record: dict, header: list[str]):\n",
    "    new_file = not os.path.exists(path)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "        f.write(\",\".join(str(record.get(k, \"\")) for k in header) + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark runner\n",
    "# ============================================================\n",
    "\n",
    "def run_full_benchmark(\n",
    "    N_list=(20, 25, 30, 35, 40, 45, 50),\n",
    "    K=100,\n",
    "    G_max=200,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    timeout_s=None,          # e.g. 600 for 10 minutes per run\n",
    "    out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\",\n",
    "):\n",
    "    header = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"K\",\n",
    "        \"G_max\",\n",
    "        \"timeout_s\",\n",
    "        \"reference_energy\",\n",
    "\n",
    "        \"cpu_seed_energy\",\n",
    "        \"cpu_seed_runtime_s\",\n",
    "        \"cpu_seed_gens\",\n",
    "        \"cpu_seed_status\",\n",
    "        \"cpu_seed_gap_pct\",\n",
    "        \"cpu_seed_error\",\n",
    "\n",
    "        \"gpu_seed_energy\",\n",
    "        \"gpu_seed_runtime_s\",\n",
    "        \"gpu_seed_gens\",\n",
    "        \"gpu_seed_status\",\n",
    "        \"gpu_seed_gap_pct\",\n",
    "        \"gpu_seed_error\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing CSV incrementally to: {out_csv}\")\n",
    "    if not HAS_CUPY:\n",
    "        print(\"[WARN] CuPy not available: GPU-seeded runs will be skipped.\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, \"\")\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            base_record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"K\": K,\n",
    "                \"G_max\": G_max,\n",
    "                \"timeout_s\": timeout_s if timeout_s is not None else \"\",\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_seed_energy\": \"\",\n",
    "                \"cpu_seed_runtime_s\": \"\",\n",
    "                \"cpu_seed_gens\": \"\",\n",
    "                \"cpu_seed_status\": \"NOT_RUN\",\n",
    "                \"cpu_seed_gap_pct\": \"\",\n",
    "                \"cpu_seed_error\": \"\",\n",
    "                \"gpu_seed_energy\": \"\",\n",
    "                \"gpu_seed_runtime_s\": \"\",\n",
    "                \"gpu_seed_gens\": \"\",\n",
    "                \"gpu_seed_status\": \"NOT_RUN\",\n",
    "                \"gpu_seed_gap_pct\": \"\",\n",
    "                \"gpu_seed_error\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU-seeded full run\n",
    "            # -------------------------\n",
    "            record = dict(base_record)\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "\n",
    "                print(\"[CPU-SEEDED] generating population on CPU + solving...\")\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _, gens_cpu, status_cpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=None,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_seed_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_seed_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"cpu_seed_gens\"] = gens_cpu\n",
    "                record[\"cpu_seed_status\"] = status_cpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record[\"cpu_seed_gap_pct\"] = 100.0 * (E_cpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[CPU-SEEDED] done. E={E_cpu:.0f} time={record['cpu_seed_runtime_s']:.3f}s status={status_cpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"cpu_seed_status\"] = \"FAIL\"\n",
    "                record[\"cpu_seed_error\"] = repr(e)\n",
    "                print(f\"[CPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after CPU step\n",
    "            append_csv(out_csv, record, header)\n",
    "            print(\"[LOG] wrote after CPU-seeded run\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU-seeded full run (seed-only GPU)\n",
    "            # -------------------------\n",
    "            record2 = dict(record)  # start from CPU record, then fill GPU columns\n",
    "            if not HAS_CUPY:\n",
    "                record2[\"gpu_seed_status\"] = \"SKIP_NO_CUPY\"\n",
    "                append_csv(out_csv, record2, header)\n",
    "                print(\"[GPU-SEEDED] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # IMPORTANT: reseed CPU RNG for the solver decisions\n",
    "                # (keeps GPU-seeded runs reproducible across repeated experiments)\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] generating population on GPU...\")\n",
    "                pop_gpu_seed = generate_population_gpu_seedonly(N=N, K=K, seed=seed + 3000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] solving on CPU with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _, gens_gpu, status_gpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=pop_gpu_seed,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record2[\"gpu_seed_energy\"] = float(E_gpu)\n",
    "                record2[\"gpu_seed_runtime_s\"] = float(g1 - g0)\n",
    "                record2[\"gpu_seed_gens\"] = gens_gpu\n",
    "                record2[\"gpu_seed_status\"] = status_gpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record2[\"gpu_seed_gap_pct\"] = 100.0 * (E_gpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[GPU-SEEDED] done. E={E_gpu:.0f} time={record2['gpu_seed_runtime_s']:.3f}s status={status_gpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record2[\"gpu_seed_status\"] = \"FAIL\"\n",
    "                record2[\"gpu_seed_error\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after GPU step\n",
    "            append_csv(out_csv, record2, header)\n",
    "            print(\"[LOG] wrote after GPU-seeded run\")\n",
    "\n",
    "    print(\"\\n[DONE] All requested N finished (or timed out).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suggested start: keep G_max modest; scale up once stable.\n",
    "    run_full_benchmark(\n",
    "        N_list=(20, 22, 24, 26, 28, 30, 32, 34),\n",
    "        K=100,\n",
    "        G_max=200,\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        timeout_s=900,  # 15 minutes per run; set None to disable\n",
    "        out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly_04.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710f66a-57ce-4212-823d-c87cbffa5469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing CSV incrementally to: mts_fullrun_cpu_vs_gpu_seedonly_05.csv\n",
      "\n",
      "===== N=35 (ref=73) =====\n",
      "\n",
      "[RUN] N=35 trial=0 @ 2026-02-01 07:36:15\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/1000] best E=97 elapsed=6.7s\n",
      "    [gen 100/1000] best E=97 elapsed=14.5s\n",
      "    [gen 150/1000] best E=97 elapsed=21.9s\n",
      "    [gen 200/1000] best E=97 elapsed=29.7s\n",
      "    [gen 250/1000] best E=97 elapsed=36.9s\n",
      "    [gen 300/1000] best E=89 elapsed=44.4s\n",
      "    [gen 350/1000] best E=89 elapsed=52.0s\n",
      "    [gen 400/1000] best E=89 elapsed=59.2s\n",
      "    [gen 450/1000] best E=89 elapsed=66.9s\n",
      "    [gen 500/1000] best E=89 elapsed=75.1s\n",
      "    [gen 550/1000] best E=89 elapsed=82.9s\n",
      "    [gen 600/1000] best E=89 elapsed=91.6s\n",
      "    [gen 650/1000] best E=89 elapsed=98.9s\n",
      "    [gen 700/1000] best E=89 elapsed=106.5s\n",
      "    [gen 750/1000] best E=89 elapsed=114.8s\n",
      "    [gen 800/1000] best E=89 elapsed=122.8s\n",
      "    [gen 850/1000] best E=89 elapsed=130.5s\n",
      "    [gen 900/1000] best E=89 elapsed=139.0s\n",
      "    [gen 950/1000] best E=89 elapsed=147.8s\n",
      "    [gen 1000/1000] best E=89 elapsed=156.0s\n",
      "[CPU-SEEDED] done. E=89 time=156.021s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/1000] best E=97 elapsed=6.7s\n",
      "    [gen 100/1000] best E=97 elapsed=14.5s\n",
      "    [gen 150/1000] best E=97 elapsed=22.0s\n",
      "    [gen 200/1000] best E=97 elapsed=29.7s\n",
      "    [gen 250/1000] best E=97 elapsed=37.0s\n",
      "    [gen 300/1000] best E=97 elapsed=44.4s\n",
      "    [gen 350/1000] best E=97 elapsed=52.0s\n",
      "    [gen 400/1000] best E=97 elapsed=59.2s\n",
      "    [gen 450/1000] best E=97 elapsed=66.9s\n",
      "    [gen 500/1000] best E=97 elapsed=75.0s\n",
      "    [gen 550/1000] best E=97 elapsed=82.9s\n",
      "    [gen 600/1000] best E=97 elapsed=91.8s\n",
      "    [gen 650/1000] best E=97 elapsed=99.1s\n",
      "    [gen 700/1000] best E=97 elapsed=106.6s\n",
      "    [gen 750/1000] best E=97 elapsed=115.0s\n",
      "    [gen 800/1000] best E=89 elapsed=123.0s\n",
      "    [gen 850/1000] best E=89 elapsed=130.7s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_cpu(N: int, K: int) -> list[np.ndarray]:\n",
    "    \"\"\"CPU RNG population: list of K arrays shape (N,) with ±1 int8.\"\"\"\n",
    "    pop = np.random.choice([-1, 1], size=(K, N)).astype(np.int8)\n",
    "    return [pop[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "def generate_population_gpu_seedonly(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    GPU RNG population on GPU, then transfer ONCE to CPU.\n",
    "    Returns list of numpy arrays shape (N,), dtype int8.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run GPU-seeded mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Tabu + MTS (CPU)\n",
    "#   - same structure as your code, but with:\n",
    "#       * aspiration fix (best admissible tabu move competes)\n",
    "#       * optional timeout checks per generation\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_cpu(s0: np.ndarray, max_iter: int = None) -> np.ndarray:\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration: tabu moves only allowed if they beat global best,\n",
    "            # but must still be best among admissible candidates\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int,\n",
    "    G_max: int,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float | None = None,\n",
    "    init_population: list[np.ndarray] | None = None,\n",
    "    timeout_s: float | None = None,\n",
    "    print_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full CPU MTS.\n",
    "    Returns: (best_energy, best_sequence, generations_completed, status)\n",
    "      status ∈ {\"OK\", \"TIMEOUT\"}\n",
    "    \"\"\"\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if init_population is None:\n",
    "        population = generate_population_cpu(N, K)\n",
    "    else:\n",
    "        population = init_population\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for g in range(1, G_max + 1):\n",
    "        if timeout_s is not None and (time.perf_counter() - start) > timeout_s:\n",
    "            return float(E_best), s_best, g - 1, \"TIMEOUT\"\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        # mutation\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        # local search\n",
    "        child = tabu_search_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "        if print_every and (g % print_every == 0):\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"    [gen {g}/{G_max}] best E={E_best:.0f} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    return float(E_best), s_best, G_max, \"OK\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV logging (incremental, crash-safe)\n",
    "# ============================================================\n",
    "\n",
    "def append_csv(path: str, record: dict, header: list[str]):\n",
    "    new_file = not os.path.exists(path)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "        f.write(\",\".join(str(record.get(k, \"\")) for k in header) + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark runner\n",
    "# ============================================================\n",
    "\n",
    "def run_full_benchmark(\n",
    "    N_list=(35, 38, 41, 44),\n",
    "    K=100,\n",
    "    G_max=200,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    timeout_s=None,          # e.g. 600 for 10 minutes per run\n",
    "    out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\",\n",
    "):\n",
    "    header = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"K\",\n",
    "        \"G_max\",\n",
    "        \"timeout_s\",\n",
    "        \"reference_energy\",\n",
    "\n",
    "        \"cpu_seed_energy\",\n",
    "        \"cpu_seed_runtime_s\",\n",
    "        \"cpu_seed_gens\",\n",
    "        \"cpu_seed_status\",\n",
    "        \"cpu_seed_gap_pct\",\n",
    "        \"cpu_seed_error\",\n",
    "\n",
    "        \"gpu_seed_energy\",\n",
    "        \"gpu_seed_runtime_s\",\n",
    "        \"gpu_seed_gens\",\n",
    "        \"gpu_seed_status\",\n",
    "        \"gpu_seed_gap_pct\",\n",
    "        \"gpu_seed_error\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing CSV incrementally to: {out_csv}\")\n",
    "    if not HAS_CUPY:\n",
    "        print(\"[WARN] CuPy not available: GPU-seeded runs will be skipped.\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, \"\")\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            base_record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"K\": K,\n",
    "                \"G_max\": G_max,\n",
    "                \"timeout_s\": timeout_s if timeout_s is not None else \"\",\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_seed_energy\": \"\",\n",
    "                \"cpu_seed_runtime_s\": \"\",\n",
    "                \"cpu_seed_gens\": \"\",\n",
    "                \"cpu_seed_status\": \"NOT_RUN\",\n",
    "                \"cpu_seed_gap_pct\": \"\",\n",
    "                \"cpu_seed_error\": \"\",\n",
    "                \"gpu_seed_energy\": \"\",\n",
    "                \"gpu_seed_runtime_s\": \"\",\n",
    "                \"gpu_seed_gens\": \"\",\n",
    "                \"gpu_seed_status\": \"NOT_RUN\",\n",
    "                \"gpu_seed_gap_pct\": \"\",\n",
    "                \"gpu_seed_error\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU-seeded full run\n",
    "            # -------------------------\n",
    "            record = dict(base_record)\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "\n",
    "                print(\"[CPU-SEEDED] generating population on CPU + solving...\")\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _, gens_cpu, status_cpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=None,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_seed_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_seed_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"cpu_seed_gens\"] = gens_cpu\n",
    "                record[\"cpu_seed_status\"] = status_cpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record[\"cpu_seed_gap_pct\"] = 100.0 * (E_cpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[CPU-SEEDED] done. E={E_cpu:.0f} time={record['cpu_seed_runtime_s']:.3f}s status={status_cpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"cpu_seed_status\"] = \"FAIL\"\n",
    "                record[\"cpu_seed_error\"] = repr(e)\n",
    "                print(f\"[CPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after CPU step\n",
    "            append_csv(out_csv, record, header)\n",
    "            print(\"[LOG] wrote after CPU-seeded run\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU-seeded full run (seed-only GPU)\n",
    "            # -------------------------\n",
    "            record2 = dict(record)  # start from CPU record, then fill GPU columns\n",
    "            if not HAS_CUPY:\n",
    "                record2[\"gpu_seed_status\"] = \"SKIP_NO_CUPY\"\n",
    "                append_csv(out_csv, record2, header)\n",
    "                print(\"[GPU-SEEDED] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # IMPORTANT: reseed CPU RNG for the solver decisions\n",
    "                # (keeps GPU-seeded runs reproducible across repeated experiments)\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] generating population on GPU...\")\n",
    "                pop_gpu_seed = generate_population_gpu_seedonly(N=N, K=K, seed=seed + 3000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] solving on CPU with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _, gens_gpu, status_gpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=pop_gpu_seed,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record2[\"gpu_seed_energy\"] = float(E_gpu)\n",
    "                record2[\"gpu_seed_runtime_s\"] = float(g1 - g0)\n",
    "                record2[\"gpu_seed_gens\"] = gens_gpu\n",
    "                record2[\"gpu_seed_status\"] = status_gpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record2[\"gpu_seed_gap_pct\"] = 100.0 * (E_gpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[GPU-SEEDED] done. E={E_gpu:.0f} time={record2['gpu_seed_runtime_s']:.3f}s status={status_gpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record2[\"gpu_seed_status\"] = \"FAIL\"\n",
    "                record2[\"gpu_seed_error\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after GPU step\n",
    "            append_csv(out_csv, record2, header)\n",
    "            print(\"[LOG] wrote after GPU-seeded run\")\n",
    "\n",
    "    print(\"\\n[DONE] All requested N finished (or timed out).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suggested start: keep G_max modest; scale up once stable.\n",
    "    run_full_benchmark(\n",
    "        N_list=(35, 38, 41, 44),\n",
    "        K=100,\n",
    "        G_max=1000,\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        timeout_s=900,  # 15 minutes per run; set None to disable\n",
    "        out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly_05.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a4f28a-1a27-4f5e-885e-0a853211246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Writing CSV incrementally to: mts_fullrun_cpu_vs_gpu_seedonly_05.csv\n",
      "\n",
      "===== N=5 (ref=2) =====\n",
      "\n",
      "[RUN] N=5 trial=0 @ 2026-02-01 13:56:12\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=2 elapsed=0.0s\n",
      "    [gen 100/200] best E=2 elapsed=0.1s\n",
      "    [gen 150/200] best E=2 elapsed=0.1s\n",
      "    [gen 200/200] best E=2 elapsed=0.1s\n",
      "[CPU-SEEDED] done. E=2 time=0.128s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=2 elapsed=0.0s\n",
      "    [gen 100/200] best E=2 elapsed=0.0s\n",
      "    [gen 150/200] best E=2 elapsed=0.1s\n",
      "    [gen 200/200] best E=2 elapsed=0.1s\n",
      "[GPU-SEEDED] done. E=2 time=0.093s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=10 (ref=13) =====\n",
      "\n",
      "[RUN] N=10 trial=0 @ 2026-02-01 13:56:12\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=13 elapsed=0.1s\n",
      "    [gen 100/200] best E=13 elapsed=0.3s\n",
      "    [gen 150/200] best E=13 elapsed=0.4s\n",
      "    [gen 200/200] best E=13 elapsed=0.6s\n",
      "[CPU-SEEDED] done. E=13 time=0.620s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=13 elapsed=0.1s\n",
      "    [gen 100/200] best E=13 elapsed=0.3s\n",
      "    [gen 150/200] best E=13 elapsed=0.4s\n",
      "    [gen 200/200] best E=13 elapsed=0.6s\n",
      "[GPU-SEEDED] done. E=13 time=0.620s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=15 (ref=15) =====\n",
      "\n",
      "[RUN] N=15 trial=0 @ 2026-02-01 13:56:14\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=15 elapsed=0.5s\n",
      "    [gen 100/200] best E=15 elapsed=1.1s\n",
      "    [gen 150/200] best E=15 elapsed=1.7s\n",
      "    [gen 200/200] best E=15 elapsed=2.2s\n",
      "[CPU-SEEDED] done. E=15 time=2.248s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=23 elapsed=0.5s\n",
      "    [gen 100/200] best E=15 elapsed=1.0s\n",
      "    [gen 150/200] best E=15 elapsed=1.3s\n",
      "    [gen 200/200] best E=15 elapsed=1.6s\n",
      "[GPU-SEEDED] done. E=15 time=1.620s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=20 (ref=26) =====\n",
      "\n",
      "[RUN] N=20 trial=0 @ 2026-02-01 13:56:17\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=34 elapsed=0.7s\n",
      "    [gen 100/200] best E=26 elapsed=1.5s\n",
      "    [gen 150/200] best E=26 elapsed=2.2s\n",
      "    [gen 200/200] best E=26 elapsed=2.9s\n",
      "[CPU-SEEDED] done. E=26 time=2.922s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=26 elapsed=0.7s\n",
      "    [gen 100/200] best E=26 elapsed=1.5s\n",
      "    [gen 150/200] best E=26 elapsed=2.2s\n",
      "    [gen 200/200] best E=26 elapsed=3.0s\n",
      "[GPU-SEEDED] done. E=26 time=2.956s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=25 (ref=36) =====\n",
      "\n",
      "[RUN] N=25 trial=0 @ 2026-02-01 13:56:23\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=44 elapsed=1.3s\n",
      "    [gen 100/200] best E=44 elapsed=2.7s\n",
      "    [gen 150/200] best E=36 elapsed=3.9s\n",
      "    [gen 200/200] best E=36 elapsed=5.4s\n",
      "[CPU-SEEDED] done. E=36 time=5.357s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=48 elapsed=1.3s\n",
      "    [gen 100/200] best E=48 elapsed=2.7s\n",
      "    [gen 150/200] best E=48 elapsed=4.0s\n",
      "    [gen 200/200] best E=48 elapsed=5.4s\n",
      "[GPU-SEEDED] done. E=48 time=5.357s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=30 (ref=59) =====\n",
      "\n",
      "[RUN] N=30 trial=0 @ 2026-02-01 13:56:34\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=75 elapsed=2.5s\n",
      "    [gen 100/200] best E=75 elapsed=4.6s\n",
      "    [gen 150/200] best E=75 elapsed=6.8s\n",
      "    [gen 200/200] best E=75 elapsed=9.0s\n",
      "[CPU-SEEDED] done. E=75 time=9.030s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=59 elapsed=2.6s\n",
      "    [gen 100/200] best E=59 elapsed=4.7s\n",
      "    [gen 150/200] best E=59 elapsed=6.9s\n",
      "    [gen 200/200] best E=59 elapsed=9.1s\n",
      "[GPU-SEEDED] done. E=59 time=9.090s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=35 (ref=73) =====\n",
      "\n",
      "[RUN] N=35 trial=0 @ 2026-02-01 13:56:52\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=97 elapsed=3.3s\n",
      "    [gen 100/200] best E=97 elapsed=7.2s\n",
      "    [gen 150/200] best E=97 elapsed=10.9s\n",
      "    [gen 200/200] best E=97 elapsed=14.7s\n",
      "[CPU-SEEDED] done. E=97 time=14.728s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=97 elapsed=3.3s\n",
      "    [gen 100/200] best E=97 elapsed=7.1s\n",
      "    [gen 150/200] best E=97 elapsed=10.8s\n",
      "    [gen 200/200] best E=97 elapsed=14.7s\n",
      "[GPU-SEEDED] done. E=97 time=14.665s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=40 (ref=108) =====\n",
      "\n",
      "[RUN] N=40 trial=0 @ 2026-02-01 13:57:22\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=152 elapsed=5.8s\n",
      "    [gen 100/200] best E=132 elapsed=11.5s\n",
      "    [gen 150/200] best E=132 elapsed=16.7s\n",
      "    [gen 200/200] best E=132 elapsed=22.1s\n",
      "[CPU-SEEDED] done. E=132 time=22.066s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=128 elapsed=5.9s\n",
      "    [gen 100/200] best E=128 elapsed=11.6s\n",
      "    [gen 150/200] best E=128 elapsed=16.9s\n",
      "    [gen 200/200] best E=128 elapsed=22.2s\n",
      "[GPU-SEEDED] done. E=128 time=22.221s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "===== N=45 (ref=118) =====\n",
      "\n",
      "[RUN] N=45 trial=0 @ 2026-02-01 13:58:06\n",
      "[CPU-SEEDED] generating population on CPU + solving...\n",
      "    [gen 50/200] best E=190 elapsed=7.0s\n",
      "    [gen 100/200] best E=158 elapsed=15.9s\n",
      "    [gen 150/200] best E=158 elapsed=24.1s\n",
      "    [gen 200/200] best E=158 elapsed=31.5s\n",
      "[CPU-SEEDED] done. E=158 time=31.540s status=OK\n",
      "[LOG] wrote after CPU-seeded run\n",
      "[GPU-SEEDED] generating population on GPU...\n",
      "[GPU-SEEDED] solving on CPU with GPU-seeded population...\n",
      "    [gen 50/200] best E=186 elapsed=7.0s\n",
      "    [gen 100/200] best E=186 elapsed=15.9s\n",
      "    [gen 150/200] best E=174 elapsed=24.1s\n",
      "    [gen 200/200] best E=174 elapsed=31.4s\n",
      "[GPU-SEEDED] done. E=174 time=31.451s status=OK\n",
      "[LOG] wrote after GPU-seeded run\n",
      "\n",
      "[DONE] All requested N finished (or timed out).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Optional GPU backend (CuPy)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LABS reference table\n",
    "# -----------------------------\n",
    "LABS_OPTIMAL = {\n",
    "    2: 1, 3: 1, 4: 2, 5: 2, 6: 7, 7: 3, 8: 8, 9: 12, 10: 13,\n",
    "    11: 5, 12: 10, 13: 6, 14: 19, 15: 15, 16: 24, 17: 32, 18: 25, 19: 29, 20: 26,\n",
    "    21: 26, 22: 39, 23: 47, 24: 36, 25: 36, 26: 45, 27: 37, 28: 50, 29: 62, 30: 59,\n",
    "    31: 67, 32: 64, 33: 64, 34: 65, 35: 73, 36: 82, 37: 86, 38: 87, 39: 99, 40: 108,\n",
    "    41: 108, 42: 101, 43: 109, 44: 122, 45: 118, 46: 131, 47: 135, 48: 140, 49: 136, 50: 153,\n",
    "    51: 153, 52: 166, 53: 170, 54: 175, 55: 171, 56: 192, 57: 188, 58: 197, 59: 205, 60: 218,\n",
    "    61: 226, 62: 235, 63: 207, 64: 208, 65: 240, 66: 257\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Energy (CPU)\n",
    "# ============================================================\n",
    "\n",
    "def energy_numpy(s: np.ndarray) -> float:\n",
    "    N = len(s)\n",
    "    e = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = int(np.sum(s[:N-k] * s[k:]))\n",
    "        e += Ck * Ck\n",
    "    return float(e)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Population generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_population_cpu(N: int, K: int) -> list[np.ndarray]:\n",
    "    \"\"\"CPU RNG population: list of K arrays shape (N,) with ±1 int8.\"\"\"\n",
    "    pop = np.random.choice([-1, 1], size=(K, N)).astype(np.int8)\n",
    "    return [pop[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "def generate_population_gpu_seedonly(N: int, K: int, seed: int) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    GPU RNG population on GPU, then transfer ONCE to CPU.\n",
    "    Returns list of numpy arrays shape (N,), dtype int8.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise RuntimeError(\"CuPy not available; cannot run GPU-seeded mode.\")\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "    pop_gpu = cp.random.randint(0, 2, size=(K, N), dtype=cp.int8)\n",
    "    pop_gpu = pop_gpu * 2 - 1  # {0,1} -> {-1,+1}\n",
    "    pop_cpu = cp.asnumpy(pop_gpu)\n",
    "    return [pop_cpu[i].copy() for i in range(K)]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Tabu + MTS (CPU)\n",
    "#   - same structure as your code, but with:\n",
    "#       * aspiration fix (best admissible tabu move competes)\n",
    "#       * optional timeout checks per generation\n",
    "# ============================================================\n",
    "\n",
    "def flip_inplace(arr, i):\n",
    "    arr[i] *= -1\n",
    "\n",
    "\n",
    "def tabu_search_cpu(s0: np.ndarray, max_iter: int = None) -> np.ndarray:\n",
    "    N = int(s0.shape[0])\n",
    "    s = s0.copy()\n",
    "    s_best = s.copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "\n",
    "    tabu_list = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    if max_iter is None:\n",
    "        M = random.randint(max(1, N // 10), max(2, 3 * N // 2))\n",
    "    else:\n",
    "        M = int(max_iter)\n",
    "\n",
    "    for t in range(1, M + 1):\n",
    "        best_i = -1\n",
    "        best_neighbor_energy = float(\"inf\")\n",
    "\n",
    "        for i in range(N):\n",
    "            flip_inplace(s, i)\n",
    "            E_neighbor = energy_numpy(s)\n",
    "            flip_inplace(s, i)\n",
    "\n",
    "            is_tabu = tabu_list[i] > t\n",
    "\n",
    "            # aspiration: tabu moves only allowed if they beat global best,\n",
    "            # but must still be best among admissible candidates\n",
    "            if is_tabu:\n",
    "                if E_neighbor < E_best and E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "            else:\n",
    "                if E_neighbor < best_neighbor_energy:\n",
    "                    best_neighbor_energy = E_neighbor\n",
    "                    best_i = i\n",
    "\n",
    "        if best_i >= 0:\n",
    "            flip_inplace(s, best_i)\n",
    "            tenure = random.randint(max(1, M // 10), max(2, M // 2))\n",
    "            tabu_list[best_i] = t + tenure\n",
    "\n",
    "            if best_neighbor_energy < E_best:\n",
    "                s_best = s.copy()\n",
    "                E_best = best_neighbor_energy\n",
    "\n",
    "    return s_best\n",
    "\n",
    "\n",
    "def memetic_tabu_search_cpu(\n",
    "    N: int,\n",
    "    K: int,\n",
    "    G_max: int,\n",
    "    p_comb: float = 0.9,\n",
    "    p_mut: float | None = None,\n",
    "    init_population: list[np.ndarray] | None = None,\n",
    "    timeout_s: float | None = None,\n",
    "    print_every: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full CPU MTS.\n",
    "    Returns: (best_energy, best_sequence, generations_completed, status)\n",
    "      status ∈ {\"OK\", \"TIMEOUT\"}\n",
    "    \"\"\"\n",
    "    if p_mut is None:\n",
    "        p_mut = 1.0 / N\n",
    "\n",
    "    if init_population is None:\n",
    "        population = generate_population_cpu(N, K)\n",
    "    else:\n",
    "        population = init_population\n",
    "\n",
    "    # initial best\n",
    "    s_best = population[0].copy()\n",
    "    E_best = energy_numpy(s_best)\n",
    "    for ind in population[1:]:\n",
    "        E = energy_numpy(ind)\n",
    "        if E < E_best:\n",
    "            s_best = ind.copy()\n",
    "            E_best = E\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for g in range(1, G_max + 1):\n",
    "        if timeout_s is not None and (time.perf_counter() - start) > timeout_s:\n",
    "            return float(E_best), s_best, g - 1, \"TIMEOUT\"\n",
    "\n",
    "        if random.random() < p_comb:\n",
    "            p1 = random.choice(population)\n",
    "            p2 = random.choice(population)\n",
    "            cut = random.randint(1, N - 1)\n",
    "            child = np.concatenate([p1[:cut], p2[cut:]]).copy()\n",
    "        else:\n",
    "            child = random.choice(population).copy()\n",
    "\n",
    "        # mutation\n",
    "        for i in range(N):\n",
    "            if random.random() < p_mut:\n",
    "                child[i] *= -1\n",
    "\n",
    "        # local search\n",
    "        child = tabu_search_cpu(child)\n",
    "        E_child = energy_numpy(child)\n",
    "\n",
    "        if E_child < E_best:\n",
    "            s_best = child.copy()\n",
    "            E_best = E_child\n",
    "\n",
    "        population[random.randint(0, K - 1)] = child\n",
    "\n",
    "        if print_every and (g % print_every == 0):\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"    [gen {g}/{G_max}] best E={E_best:.0f} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    return float(E_best), s_best, G_max, \"OK\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CSV logging (incremental, crash-safe)\n",
    "# ============================================================\n",
    "\n",
    "def append_csv(path: str, record: dict, header: list[str]):\n",
    "    new_file = not os.path.exists(path)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if new_file:\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "        f.write(\",\".join(str(record.get(k, \"\")) for k in header) + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Benchmark runner\n",
    "# ============================================================\n",
    "\n",
    "def run_full_benchmark(\n",
    "    N_list=(5, 10, 15, 20, 25, 30, 35, 40, 45),\n",
    "    K=100,\n",
    "    G_max=200,\n",
    "    trials=1,\n",
    "    seed=42,\n",
    "    timeout_s=None,          # e.g. 600 for 10 minutes per run\n",
    "    out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly.csv\",\n",
    "):\n",
    "    header = [\n",
    "        \"timestamp\",\n",
    "        \"N\",\n",
    "        \"trial\",\n",
    "        \"K\",\n",
    "        \"G_max\",\n",
    "        \"timeout_s\",\n",
    "        \"reference_energy\",\n",
    "\n",
    "        \"cpu_seed_energy\",\n",
    "        \"cpu_seed_runtime_s\",\n",
    "        \"cpu_seed_gens\",\n",
    "        \"cpu_seed_status\",\n",
    "        \"cpu_seed_gap_pct\",\n",
    "        \"cpu_seed_error\",\n",
    "\n",
    "        \"gpu_seed_energy\",\n",
    "        \"gpu_seed_runtime_s\",\n",
    "        \"gpu_seed_gens\",\n",
    "        \"gpu_seed_status\",\n",
    "        \"gpu_seed_gap_pct\",\n",
    "        \"gpu_seed_error\",\n",
    "    ]\n",
    "\n",
    "    print(f\"[LOG] Writing CSV incrementally to: {out_csv}\")\n",
    "    if not HAS_CUPY:\n",
    "        print(\"[WARN] CuPy not available: GPU-seeded runs will be skipped.\")\n",
    "\n",
    "    for N in N_list:\n",
    "        ref = LABS_OPTIMAL.get(N, \"\")\n",
    "        print(f\"\\n===== N={N} (ref={ref}) =====\")\n",
    "\n",
    "        for t in range(trials):\n",
    "            stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\n[RUN] N={N} trial={t} @ {stamp}\")\n",
    "\n",
    "            base_record = {\n",
    "                \"timestamp\": stamp,\n",
    "                \"N\": N,\n",
    "                \"trial\": t,\n",
    "                \"K\": K,\n",
    "                \"G_max\": G_max,\n",
    "                \"timeout_s\": timeout_s if timeout_s is not None else \"\",\n",
    "                \"reference_energy\": ref,\n",
    "                \"cpu_seed_energy\": \"\",\n",
    "                \"cpu_seed_runtime_s\": \"\",\n",
    "                \"cpu_seed_gens\": \"\",\n",
    "                \"cpu_seed_status\": \"NOT_RUN\",\n",
    "                \"cpu_seed_gap_pct\": \"\",\n",
    "                \"cpu_seed_error\": \"\",\n",
    "                \"gpu_seed_energy\": \"\",\n",
    "                \"gpu_seed_runtime_s\": \"\",\n",
    "                \"gpu_seed_gens\": \"\",\n",
    "                \"gpu_seed_status\": \"NOT_RUN\",\n",
    "                \"gpu_seed_gap_pct\": \"\",\n",
    "                \"gpu_seed_error\": \"\",\n",
    "            }\n",
    "\n",
    "            # -------------------------\n",
    "            # CPU-seeded full run\n",
    "            # -------------------------\n",
    "            record = dict(base_record)\n",
    "            try:\n",
    "                np.random.seed(seed + 1000*t + N)\n",
    "                random.seed(seed + 1000*t + N)\n",
    "\n",
    "                print(\"[CPU-SEEDED] generating population on CPU + solving...\")\n",
    "                t0 = time.perf_counter()\n",
    "                E_cpu, _, gens_cpu, status_cpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=None,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                t1 = time.perf_counter()\n",
    "\n",
    "                record[\"cpu_seed_energy\"] = float(E_cpu)\n",
    "                record[\"cpu_seed_runtime_s\"] = float(t1 - t0)\n",
    "                record[\"cpu_seed_gens\"] = gens_cpu\n",
    "                record[\"cpu_seed_status\"] = status_cpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record[\"cpu_seed_gap_pct\"] = 100.0 * (E_cpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[CPU-SEEDED] done. E={E_cpu:.0f} time={record['cpu_seed_runtime_s']:.3f}s status={status_cpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record[\"cpu_seed_status\"] = \"FAIL\"\n",
    "                record[\"cpu_seed_error\"] = repr(e)\n",
    "                print(f\"[CPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after CPU step\n",
    "            append_csv(out_csv, record, header)\n",
    "            print(\"[LOG] wrote after CPU-seeded run\")\n",
    "\n",
    "            # -------------------------\n",
    "            # GPU-seeded full run (seed-only GPU)\n",
    "            # -------------------------\n",
    "            record2 = dict(record)  # start from CPU record, then fill GPU columns\n",
    "            if not HAS_CUPY:\n",
    "                record2[\"gpu_seed_status\"] = \"SKIP_NO_CUPY\"\n",
    "                append_csv(out_csv, record2, header)\n",
    "                print(\"[GPU-SEEDED] skipped (no CuPy).\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # IMPORTANT: reseed CPU RNG for the solver decisions\n",
    "                # (keeps GPU-seeded runs reproducible across repeated experiments)\n",
    "                np.random.seed(seed + 2000*t + N)\n",
    "                random.seed(seed + 2000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] generating population on GPU...\")\n",
    "                pop_gpu_seed = generate_population_gpu_seedonly(N=N, K=K, seed=seed + 3000*t + N)\n",
    "\n",
    "                print(\"[GPU-SEEDED] solving on CPU with GPU-seeded population...\")\n",
    "                g0 = time.perf_counter()\n",
    "                E_gpu, _, gens_gpu, status_gpu = memetic_tabu_search_cpu(\n",
    "                    N=N, K=K, G_max=G_max,\n",
    "                    init_population=pop_gpu_seed,\n",
    "                    timeout_s=timeout_s,\n",
    "                    print_every=50,\n",
    "                )\n",
    "                g1 = time.perf_counter()\n",
    "\n",
    "                record2[\"gpu_seed_energy\"] = float(E_gpu)\n",
    "                record2[\"gpu_seed_runtime_s\"] = float(g1 - g0)\n",
    "                record2[\"gpu_seed_gens\"] = gens_gpu\n",
    "                record2[\"gpu_seed_status\"] = status_gpu\n",
    "\n",
    "                if ref != \"\" and ref != 0:\n",
    "                    record2[\"gpu_seed_gap_pct\"] = 100.0 * (E_gpu - float(ref)) / float(ref)\n",
    "\n",
    "                print(f\"[GPU-SEEDED] done. E={E_gpu:.0f} time={record2['gpu_seed_runtime_s']:.3f}s status={status_gpu}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                record2[\"gpu_seed_status\"] = \"FAIL\"\n",
    "                record2[\"gpu_seed_error\"] = repr(e)\n",
    "                print(f\"[GPU-SEEDED] FAILED: {repr(e)}\")\n",
    "\n",
    "            # Log after GPU step\n",
    "            append_csv(out_csv, record2, header)\n",
    "            print(\"[LOG] wrote after GPU-seeded run\")\n",
    "\n",
    "    print(\"\\n[DONE] All requested N finished (or timed out).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suggested start: keep G_max modest; scale up once stable.\n",
    "    run_full_benchmark(\n",
    "        N_list=(5, 10, 15, 20, 25, 30, 35, 40, 45),\n",
    "        K=100,\n",
    "        G_max=200,\n",
    "        trials=1,\n",
    "        seed=42,\n",
    "        timeout_s=900,  # 15 minutes per run; set None to disable\n",
    "        out_csv=\"mts_fullrun_cpu_vs_gpu_seedonly_05.csv\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [cuda-q-v0.13.0]",
   "language": "python",
   "name": "python3_fg2h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
